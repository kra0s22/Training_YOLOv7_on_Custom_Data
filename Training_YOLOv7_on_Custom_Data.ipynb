{"cells":[{"cell_type":"markdown","metadata":{"id":"7mGmQbAO5pQb"},"source":["#Install Dependencies\n","\n","_(Remember to choose GPU in Runtime if not already selected. Runtime --> Change Runtime Type --> Hardware accelerator --> GPU)_"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":15047,"status":"ok","timestamp":1668878133623,"user":{"displayName":"jose garcia","userId":"18071348481124640591"},"user_tz":0},"id":"nD-uPyQ_2jiN","outputId":"22af19ac-2c65-40c9-9ef9-50d2f9087271"},"outputs":[{"output_type":"stream","name":"stdout","text":["Cloning into 'yolov7'...\n","remote: Enumerating objects: 998, done.\u001b[K\n","remote: Total 998 (delta 0), reused 0 (delta 0), pack-reused 998\u001b[K\n","Receiving objects: 100% (998/998), 69.77 MiB | 15.91 MiB/s, done.\n","Resolving deltas: 100% (466/466), done.\n","/content/yolov7\n","Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Requirement already satisfied: matplotlib>=3.2.2 in /usr/local/lib/python3.7/dist-packages (from -r requirements.txt (line 4)) (3.2.2)\n","Requirement already satisfied: numpy>=1.18.5 in /usr/local/lib/python3.7/dist-packages (from -r requirements.txt (line 5)) (1.21.6)\n","Requirement already satisfied: opencv-python>=4.1.1 in /usr/local/lib/python3.7/dist-packages (from -r requirements.txt (line 6)) (4.6.0.66)\n","Requirement already satisfied: Pillow>=7.1.2 in /usr/local/lib/python3.7/dist-packages (from -r requirements.txt (line 7)) (7.1.2)\n","Requirement already satisfied: PyYAML>=5.3.1 in /usr/local/lib/python3.7/dist-packages (from -r requirements.txt (line 8)) (6.0)\n","Requirement already satisfied: requests>=2.23.0 in /usr/local/lib/python3.7/dist-packages (from -r requirements.txt (line 9)) (2.23.0)\n","Requirement already satisfied: scipy>=1.4.1 in /usr/local/lib/python3.7/dist-packages (from -r requirements.txt (line 10)) (1.7.3)\n","Requirement already satisfied: torch!=1.12.0,>=1.7.0 in /usr/local/lib/python3.7/dist-packages (from -r requirements.txt (line 11)) (1.12.1+cu113)\n","Requirement already satisfied: torchvision!=0.13.0,>=0.8.1 in /usr/local/lib/python3.7/dist-packages (from -r requirements.txt (line 12)) (0.13.1+cu113)\n","Requirement already satisfied: tqdm>=4.41.0 in /usr/local/lib/python3.7/dist-packages (from -r requirements.txt (line 13)) (4.64.1)\n","Requirement already satisfied: protobuf<4.21.3 in /usr/local/lib/python3.7/dist-packages (from -r requirements.txt (line 14)) (3.19.6)\n","Requirement already satisfied: tensorboard>=2.4.1 in /usr/local/lib/python3.7/dist-packages (from -r requirements.txt (line 17)) (2.9.1)\n","Requirement already satisfied: pandas>=1.1.4 in /usr/local/lib/python3.7/dist-packages (from -r requirements.txt (line 21)) (1.3.5)\n","Requirement already satisfied: seaborn>=0.11.0 in /usr/local/lib/python3.7/dist-packages (from -r requirements.txt (line 22)) (0.11.2)\n","Requirement already satisfied: ipython in /usr/local/lib/python3.7/dist-packages (from -r requirements.txt (line 34)) (7.9.0)\n","Requirement already satisfied: psutil in /usr/local/lib/python3.7/dist-packages (from -r requirements.txt (line 35)) (5.4.8)\n","Collecting thop\n","  Downloading thop-0.1.1.post2209072238-py3-none-any.whl (15 kB)\n","Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib>=3.2.2->-r requirements.txt (line 4)) (1.4.4)\n","Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib>=3.2.2->-r requirements.txt (line 4)) (2.8.2)\n","Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.7/dist-packages (from matplotlib>=3.2.2->-r requirements.txt (line 4)) (0.11.0)\n","Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib>=3.2.2->-r requirements.txt (line 4)) (3.0.9)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests>=2.23.0->-r requirements.txt (line 9)) (2022.9.24)\n","Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests>=2.23.0->-r requirements.txt (line 9)) (1.24.3)\n","Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests>=2.23.0->-r requirements.txt (line 9)) (3.0.4)\n","Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests>=2.23.0->-r requirements.txt (line 9)) (2.10)\n","Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torch!=1.12.0,>=1.7.0->-r requirements.txt (line 11)) (4.1.1)\n","Requirement already satisfied: tensorboard-data-server<0.7.0,>=0.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard>=2.4.1->-r requirements.txt (line 17)) (0.6.1)\n","Requirement already satisfied: grpcio>=1.24.3 in /usr/local/lib/python3.7/dist-packages (from tensorboard>=2.4.1->-r requirements.txt (line 17)) (1.50.0)\n","Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /usr/local/lib/python3.7/dist-packages (from tensorboard>=2.4.1->-r requirements.txt (line 17)) (0.4.6)\n","Requirement already satisfied: setuptools>=41.0.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard>=2.4.1->-r requirements.txt (line 17)) (57.4.0)\n","Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard>=2.4.1->-r requirements.txt (line 17)) (1.8.1)\n","Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.7/dist-packages (from tensorboard>=2.4.1->-r requirements.txt (line 17)) (1.0.1)\n","Requirement already satisfied: wheel>=0.26 in /usr/local/lib/python3.7/dist-packages (from tensorboard>=2.4.1->-r requirements.txt (line 17)) (0.38.3)\n","Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.7/dist-packages (from tensorboard>=2.4.1->-r requirements.txt (line 17)) (3.4.1)\n","Requirement already satisfied: google-auth<3,>=1.6.3 in /usr/local/lib/python3.7/dist-packages (from tensorboard>=2.4.1->-r requirements.txt (line 17)) (2.14.1)\n","Requirement already satisfied: absl-py>=0.4 in /usr/local/lib/python3.7/dist-packages (from tensorboard>=2.4.1->-r requirements.txt (line 17)) (1.3.0)\n","Requirement already satisfied: pytz>=2017.3 in /usr/local/lib/python3.7/dist-packages (from pandas>=1.1.4->-r requirements.txt (line 21)) (2022.6)\n","Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard>=2.4.1->-r requirements.txt (line 17)) (0.2.8)\n","Requirement already satisfied: six>=1.9.0 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard>=2.4.1->-r requirements.txt (line 17)) (1.15.0)\n","Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard>=2.4.1->-r requirements.txt (line 17)) (5.2.0)\n","Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard>=2.4.1->-r requirements.txt (line 17)) (4.9)\n","Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.7/dist-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard>=2.4.1->-r requirements.txt (line 17)) (1.3.1)\n","Requirement already satisfied: importlib-metadata>=4.4 in /usr/local/lib/python3.7/dist-packages (from markdown>=2.6.8->tensorboard>=2.4.1->-r requirements.txt (line 17)) (4.13.0)\n","Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata>=4.4->markdown>=2.6.8->tensorboard>=2.4.1->-r requirements.txt (line 17)) (3.10.0)\n","Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /usr/local/lib/python3.7/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard>=2.4.1->-r requirements.txt (line 17)) (0.4.8)\n","Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.7/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard>=2.4.1->-r requirements.txt (line 17)) (3.2.2)\n","Collecting jedi>=0.10\n","  Downloading jedi-0.18.1-py2.py3-none-any.whl (1.6 MB)\n","\u001b[K     |‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1.6 MB 41.7 MB/s \n","\u001b[?25hRequirement already satisfied: pygments in /usr/local/lib/python3.7/dist-packages (from ipython->-r requirements.txt (line 34)) (2.6.1)\n","Requirement already satisfied: backcall in /usr/local/lib/python3.7/dist-packages (from ipython->-r requirements.txt (line 34)) (0.2.0)\n","Requirement already satisfied: decorator in /usr/local/lib/python3.7/dist-packages (from ipython->-r requirements.txt (line 34)) (4.4.2)\n","Requirement already satisfied: pexpect in /usr/local/lib/python3.7/dist-packages (from ipython->-r requirements.txt (line 34)) (4.8.0)\n","Requirement already satisfied: traitlets>=4.2 in /usr/local/lib/python3.7/dist-packages (from ipython->-r requirements.txt (line 34)) (5.1.1)\n","Requirement already satisfied: prompt-toolkit<2.1.0,>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from ipython->-r requirements.txt (line 34)) (2.0.10)\n","Requirement already satisfied: pickleshare in /usr/local/lib/python3.7/dist-packages (from ipython->-r requirements.txt (line 34)) (0.7.5)\n","Requirement already satisfied: parso<0.9.0,>=0.8.0 in /usr/local/lib/python3.7/dist-packages (from jedi>=0.10->ipython->-r requirements.txt (line 34)) (0.8.3)\n","Requirement already satisfied: wcwidth in /usr/local/lib/python3.7/dist-packages (from prompt-toolkit<2.1.0,>=2.0.0->ipython->-r requirements.txt (line 34)) (0.2.5)\n","Requirement already satisfied: ptyprocess>=0.5 in /usr/local/lib/python3.7/dist-packages (from pexpect->ipython->-r requirements.txt (line 34)) (0.7.0)\n","Installing collected packages: jedi, thop\n","Successfully installed jedi-0.18.1 thop-0.1.1.post2209072238\n"]}],"source":["# Download YOLOv7 repository and install requirements\n","!git clone https://github.com/WongKinYiu/yolov7\n","%cd yolov7\n","!pip install -r requirements.txt"]},{"cell_type":"markdown","metadata":{"id":"mtJ24mPlyF-S"},"source":["# Download Correctly Formatted Custom Data\n","\n","Next, we'll download our dataset in the right format. For this project the dataset will use the supported YOLOv7 format, directly download from [Roboflow](https://roboflow.com/). Specifically, the used dataset is a bulk of photos and images with wapons on it. \n"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":17973,"status":"ok","timestamp":1668897363529,"user":{"displayName":"jose garcia","userId":"17007939955126370779"},"user_tz":0},"id":"y00y6IuV2Z6E","outputId":"ae0eff3f-53b0-4093-9fc7-65479f43a69a"},"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}],"source":["from google.colab import drive\n","drive.mount('/content/drive')"]},{"cell_type":"markdown","source":["My private kay to import the dataset is allocated in a file on my google drive, so I need to open the file and save the key to a variable."],"metadata":{"id":"odIUuI2m-yIh"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"FEf_GM3D2siK"},"outputs":[],"source":["f = open(\"/content/drive/MyDrive/key.txt\", \"r\")\n","key = f.read()\n","f.close()"]},{"cell_type":"markdown","source":["Lastly, we use the RoboFlow library to download directly the dataset from the RobloFlow project."],"metadata":{"id":"ecYW9WWT_JS0"}},{"cell_type":"code","source":["!pip install roboflow"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000},"id":"ZQWrQpSSqhNP","executionInfo":{"status":"ok","timestamp":1668878279598,"user_tz":0,"elapsed":14229,"user":{"displayName":"jose garcia","userId":"18071348481124640591"}},"outputId":"ebb23a10-1a68-440e-807d-7463c2ed6867"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Collecting roboflow\n","  Downloading roboflow-0.2.20-py3-none-any.whl (41 kB)\n","\u001b[K     |‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 41 kB 631 kB/s \n","\u001b[?25hRequirement already satisfied: glob2 in /usr/local/lib/python3.7/dist-packages (from roboflow) (0.7)\n","Collecting urllib3==1.26.6\n","  Downloading urllib3-1.26.6-py2.py3-none-any.whl (138 kB)\n","\u001b[K     |‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 138 kB 59.2 MB/s \n","\u001b[?25hRequirement already satisfied: PyYAML>=5.3.1 in /usr/local/lib/python3.7/dist-packages (from roboflow) (6.0)\n","Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from roboflow) (1.15.0)\n","Collecting cycler==0.10.0\n","  Downloading cycler-0.10.0-py2.py3-none-any.whl (6.5 kB)\n","Collecting certifi==2021.5.30\n","  Downloading certifi-2021.5.30-py2.py3-none-any.whl (145 kB)\n","\u001b[K     |‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 145 kB 74.8 MB/s \n","\u001b[?25hCollecting requests-toolbelt\n","  Downloading requests_toolbelt-0.10.1-py2.py3-none-any.whl (54 kB)\n","\u001b[K     |‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 54 kB 3.5 MB/s \n","\u001b[?25hRequirement already satisfied: numpy>=1.18.5 in /usr/local/lib/python3.7/dist-packages (from roboflow) (1.21.6)\n","Requirement already satisfied: python-dateutil in /usr/local/lib/python3.7/dist-packages (from roboflow) (2.8.2)\n","Requirement already satisfied: idna==2.10 in /usr/local/lib/python3.7/dist-packages (from roboflow) (2.10)\n","Collecting pyparsing==2.4.7\n","  Downloading pyparsing-2.4.7-py2.py3-none-any.whl (67 kB)\n","\u001b[K     |‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 67 kB 6.7 MB/s \n","\u001b[?25hCollecting wget\n","  Downloading wget-3.2.zip (10 kB)\n","Requirement already satisfied: matplotlib in /usr/local/lib/python3.7/dist-packages (from roboflow) (3.2.2)\n","Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from roboflow) (2.23.0)\n","Collecting python-dotenv\n","  Downloading python_dotenv-0.21.0-py3-none-any.whl (18 kB)\n","Requirement already satisfied: Pillow>=7.1.2 in /usr/local/lib/python3.7/dist-packages (from roboflow) (7.1.2)\n","Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.7/dist-packages (from roboflow) (1.4.4)\n","Collecting chardet==4.0.0\n","  Downloading chardet-4.0.0-py2.py3-none-any.whl (178 kB)\n","\u001b[K     |‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 178 kB 68.1 MB/s \n","\u001b[?25hRequirement already satisfied: opencv-python-headless>=4.5.1.48 in /usr/local/lib/python3.7/dist-packages (from roboflow) (4.6.0.66)\n","Requirement already satisfied: tqdm>=4.41.0 in /usr/local/lib/python3.7/dist-packages (from roboflow) (4.64.1)\n","Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from kiwisolver>=1.3.1->roboflow) (4.1.1)\n","Collecting requests\n","  Downloading requests-2.28.1-py3-none-any.whl (62 kB)\n","\u001b[K     |‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 62 kB 1.6 MB/s \n","\u001b[?25hRequirement already satisfied: charset-normalizer<3,>=2 in /usr/local/lib/python3.7/dist-packages (from requests->roboflow) (2.1.1)\n","Building wheels for collected packages: wget\n","  Building wheel for wget (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for wget: filename=wget-3.2-py3-none-any.whl size=9675 sha256=c47219d8a8ae5ee26754062bb2e232211f8b09d5445e4af417dca7e958492713\n","  Stored in directory: /root/.cache/pip/wheels/a1/b6/7c/0e63e34eb06634181c63adacca38b79ff8f35c37e3c13e3c02\n","Successfully built wget\n","Installing collected packages: urllib3, certifi, requests, pyparsing, cycler, wget, requests-toolbelt, python-dotenv, chardet, roboflow\n","  Attempting uninstall: urllib3\n","    Found existing installation: urllib3 1.24.3\n","    Uninstalling urllib3-1.24.3:\n","      Successfully uninstalled urllib3-1.24.3\n","  Attempting uninstall: certifi\n","    Found existing installation: certifi 2022.9.24\n","    Uninstalling certifi-2022.9.24:\n","      Successfully uninstalled certifi-2022.9.24\n","  Attempting uninstall: requests\n","    Found existing installation: requests 2.23.0\n","    Uninstalling requests-2.23.0:\n","      Successfully uninstalled requests-2.23.0\n","  Attempting uninstall: pyparsing\n","    Found existing installation: pyparsing 3.0.9\n","    Uninstalling pyparsing-3.0.9:\n","      Successfully uninstalled pyparsing-3.0.9\n","  Attempting uninstall: cycler\n","    Found existing installation: cycler 0.11.0\n","    Uninstalling cycler-0.11.0:\n","      Successfully uninstalled cycler-0.11.0\n","  Attempting uninstall: chardet\n","    Found existing installation: chardet 3.0.4\n","    Uninstalling chardet-3.0.4:\n","      Successfully uninstalled chardet-3.0.4\n","Successfully installed certifi-2021.5.30 chardet-4.0.0 cycler-0.10.0 pyparsing-2.4.7 python-dotenv-0.21.0 requests-2.28.1 requests-toolbelt-0.10.1 roboflow-0.2.20 urllib3-1.26.6 wget-3.2\n"]},{"output_type":"display_data","data":{"application/vnd.colab-display-data+json":{"pip_warning":{"packages":["certifi","cycler","pyparsing"]}}},"metadata":{}}]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":41057,"status":"ok","timestamp":1668878326363,"user":{"displayName":"jose garcia","userId":"18071348481124640591"},"user_tz":0},"id":"ovKgrVN8ygdW","outputId":"dd4b5550-8971-43a2-bef3-6775cbf1fded"},"outputs":[{"output_type":"stream","name":"stdout","text":["loading Roboflow workspace...\n","loading Roboflow workspace...\n","loading Roboflow project...\n","Downloading Dataset Version Zip in Weapon-Dataset-2 to yolov7pytorch: 100% [99426451 / 99426451] bytes\n"]},{"output_type":"stream","name":"stderr","text":["Extracting Dataset Version Zip to Weapon-Dataset-2 in yolov7pytorch:: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 7748/7748 [00:02<00:00, 3169.96it/s]\n"]}],"source":["from roboflow import Roboflow\n","rf = Roboflow(api_key=str(key))\n","rf.workspace().projects()\n","project = rf.workspace(\"ai-project-dazch\").project(\"weapon-dataset-iff7y\")\n","dataset = project.version(2).download(\"yolov7\")"]},{"cell_type":"markdown","source":["In addition, if you whant to sasave this dataframe into your own Drive, you only have to use the cp command and define the destination of the copy."],"metadata":{"id":"eqansOgo_wjl"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"AzESE58O0q_S","executionInfo":{"status":"ok","timestamp":1668878348576,"user_tz":0,"elapsed":410,"user":{"displayName":"jose garcia","userId":"18071348481124640591"}},"colab":{"base_uri":"https://localhost:8080/"},"outputId":"959184bc-6611-476a-d312-31098b88ac19"},"outputs":[{"output_type":"stream","name":"stdout","text":["cp: cannot create directory '/content/drive/MyDrive/Github/YOLOv7_Testing_on_Colab': No such file or directory\n"]}],"source":["%cp -r /content/yolov7/Weapon-Dataset-2 /content/drive/MyDrive/Github/YOLOv7_Testing_on_Colab"]},{"cell_type":"markdown","metadata":{"id":"bHfT9gEiBsBd"},"source":["# Begin Custom Training\n","\n","We're ready to start custom training.\n","\n","The implemented training will only modify the `epochs` and `batch number` parameters for a short execution training. However, it is possible to modify a bunch of different parameters and hiperparameters for a training, you can visualize all of them from the --help command executing !python train.py or visiting the [RoboFlow blogspot](https://blog.roboflow.com/yolov7-custom-dataset-training-tutorial/)."]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":9277,"status":"ok","timestamp":1668878369373,"user":{"displayName":"jose garcia","userId":"18071348481124640591"},"user_tz":0},"id":"bUbmy674bhpD","outputId":"b6386812-7083-4579-8bcb-844ca55e683b"},"outputs":[{"output_type":"stream","name":"stdout","text":["/content/yolov7\n","--2022-11-19 17:19:20--  https://github.com/WongKinYiu/yolov7/releases/download/v0.1/yolov7_training.pt\n","Resolving github.com (github.com)... 20.205.243.166\n","Connecting to github.com (github.com)|20.205.243.166|:443... connected.\n","HTTP request sent, awaiting response... 302 Found\n","Location: https://objects.githubusercontent.com/github-production-release-asset-2e65be/511187726/13e046d1-f7f0-43ab-910b-480613181b1f?X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=AKIAIWNJYAX4CSVEH53A%2F20221119%2Fus-east-1%2Fs3%2Faws4_request&X-Amz-Date=20221119T171920Z&X-Amz-Expires=300&X-Amz-Signature=a3d3f5693b333ecb84b5bdb4b72a18a121d5a5bd8d3ff4c9a6e905f31afccd3b&X-Amz-SignedHeaders=host&actor_id=0&key_id=0&repo_id=511187726&response-content-disposition=attachment%3B%20filename%3Dyolov7_training.pt&response-content-type=application%2Foctet-stream [following]\n","--2022-11-19 17:19:20--  https://objects.githubusercontent.com/github-production-release-asset-2e65be/511187726/13e046d1-f7f0-43ab-910b-480613181b1f?X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=AKIAIWNJYAX4CSVEH53A%2F20221119%2Fus-east-1%2Fs3%2Faws4_request&X-Amz-Date=20221119T171920Z&X-Amz-Expires=300&X-Amz-Signature=a3d3f5693b333ecb84b5bdb4b72a18a121d5a5bd8d3ff4c9a6e905f31afccd3b&X-Amz-SignedHeaders=host&actor_id=0&key_id=0&repo_id=511187726&response-content-disposition=attachment%3B%20filename%3Dyolov7_training.pt&response-content-type=application%2Foctet-stream\n","Resolving objects.githubusercontent.com (objects.githubusercontent.com)... 185.199.108.133, 185.199.109.133, 185.199.110.133, ...\n","Connecting to objects.githubusercontent.com (objects.githubusercontent.com)|185.199.108.133|:443... connected.\n","HTTP request sent, awaiting response... 200 OK\n","Length: 75628875 (72M) [application/octet-stream]\n","Saving to: ‚Äòyolov7_training.pt‚Äô\n","\n","yolov7_training.pt  100%[===================>]  72.12M  8.84MB/s    in 8.1s    \n","\n","2022-11-19 17:19:29 (8.88 MB/s) - ‚Äòyolov7_training.pt‚Äô saved [75628875/75628875]\n","\n"]}],"source":["%cd /content/yolov7\n","!wget https://github.com/WongKinYiu/yolov7/releases/download/v0.1/yolov7_training.pt"]},{"cell_type":"markdown","source":["For this training, the data.yaml path is obtained from the dataset and the weights are implemented directly from the following [github directory](https://github.com/WongKinYiu/yolov7/releases/download/v0.1/yolov7_training.pt)"],"metadata":{"id":"nt8cdE-gDFyp"}},{"cell_type":"code","source":["!pip install --upgrade urllib3"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":329},"id":"ZGG9W9wlU-BD","executionInfo":{"status":"ok","timestamp":1668878376888,"user_tz":0,"elapsed":4522,"user":{"displayName":"jose garcia","userId":"18071348481124640591"}},"outputId":"9eeb8a59-93c6-4498-c6d7-e0bf6279db0f"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Requirement already satisfied: urllib3 in /usr/local/lib/python3.7/dist-packages (1.26.6)\n","Collecting urllib3\n","  Downloading urllib3-1.26.12-py2.py3-none-any.whl (140 kB)\n","\u001b[K     |‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 140 kB 30.1 MB/s \n","\u001b[?25hInstalling collected packages: urllib3\n","  Attempting uninstall: urllib3\n","    Found existing installation: urllib3 1.26.6\n","    Uninstalling urllib3-1.26.6:\n","      Successfully uninstalled urllib3-1.26.6\n","\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n","roboflow 0.2.20 requires urllib3==1.26.6, but you have urllib3 1.26.12 which is incompatible.\u001b[0m\n","Successfully installed urllib3-1.26.12\n"]},{"output_type":"display_data","data":{"application/vnd.colab-display-data+json":{"pip_warning":{"packages":["urllib3"]}}},"metadata":{}}]},{"cell_type":"code","source":["!pip install wandb"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"4CI-T2r66Gws","executionInfo":{"status":"ok","timestamp":1668878478811,"user_tz":0,"elapsed":12532,"user":{"displayName":"jose garcia","userId":"18071348481124640591"}},"outputId":"d3f66e7f-9c81-4814-8911-95374f6e60cc"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Collecting wandb\n","  Downloading wandb-0.13.5-py2.py3-none-any.whl (1.9 MB)\n","\u001b[K     |‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1.9 MB 39.8 MB/s \n","\u001b[?25hCollecting shortuuid>=0.5.0\n","  Downloading shortuuid-1.0.11-py3-none-any.whl (10 kB)\n","Requirement already satisfied: Click!=8.0.0,>=7.0 in /usr/local/lib/python3.7/dist-packages (from wandb) (7.1.2)\n","Requirement already satisfied: psutil>=5.0.0 in /usr/local/lib/python3.7/dist-packages (from wandb) (5.4.8)\n","Requirement already satisfied: PyYAML in /usr/local/lib/python3.7/dist-packages (from wandb) (6.0)\n","Collecting sentry-sdk>=1.0.0\n","  Downloading sentry_sdk-1.11.0-py2.py3-none-any.whl (168 kB)\n","\u001b[K     |‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 168 kB 66.3 MB/s \n","\u001b[?25hCollecting setproctitle\n","  Downloading setproctitle-1.3.2-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (30 kB)\n","Requirement already satisfied: requests<3,>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from wandb) (2.28.1)\n","Requirement already satisfied: setuptools in /usr/local/lib/python3.7/dist-packages (from wandb) (57.4.0)\n","Requirement already satisfied: promise<3,>=2.0 in /usr/local/lib/python3.7/dist-packages (from wandb) (2.3)\n","Collecting docker-pycreds>=0.4.0\n","  Downloading docker_pycreds-0.4.0-py2.py3-none-any.whl (9.0 kB)\n","Requirement already satisfied: six>=1.13.0 in /usr/local/lib/python3.7/dist-packages (from wandb) (1.15.0)\n","Requirement already satisfied: protobuf!=4.0.*,!=4.21.0,<5,>=3.12.0 in /usr/local/lib/python3.7/dist-packages (from wandb) (3.19.6)\n","Collecting pathtools\n","  Downloading pathtools-0.1.2.tar.gz (11 kB)\n","Collecting GitPython>=1.0.0\n","  Downloading GitPython-3.1.29-py3-none-any.whl (182 kB)\n","\u001b[K     |‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 182 kB 64.0 MB/s \n","\u001b[?25hRequirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.7/dist-packages (from GitPython>=1.0.0->wandb) (4.1.1)\n","Collecting gitdb<5,>=4.0.1\n","  Downloading gitdb-4.0.9-py3-none-any.whl (63 kB)\n","\u001b[K     |‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 63 kB 1.9 MB/s \n","\u001b[?25hCollecting smmap<6,>=3.0.1\n","  Downloading smmap-5.0.0-py3-none-any.whl (24 kB)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.0.0->wandb) (2.10)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.0.0->wandb) (2021.5.30)\n","Requirement already satisfied: charset-normalizer<3,>=2 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.0.0->wandb) (2.1.1)\n","Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.0.0->wandb) (1.26.12)\n","Building wheels for collected packages: pathtools\n","  Building wheel for pathtools (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for pathtools: filename=pathtools-0.1.2-py3-none-any.whl size=8806 sha256=6f1b4017efea71af0cbcbba245ecc02cab68494d981231d55ccb25317838b1aa\n","  Stored in directory: /root/.cache/pip/wheels/3e/31/09/fa59cef12cdcfecc627b3d24273699f390e71828921b2cbba2\n","Successfully built pathtools\n","Installing collected packages: smmap, gitdb, shortuuid, setproctitle, sentry-sdk, pathtools, GitPython, docker-pycreds, wandb\n","Successfully installed GitPython-3.1.29 docker-pycreds-0.4.0 gitdb-4.0.9 pathtools-0.1.2 sentry-sdk-1.11.0 setproctitle-1.3.2 shortuuid-1.0.11 smmap-5.0.0 wandb-0.13.5\n"]}]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"1iqOPKjr22mL","outputId":"5c563b85-e779-4690-d379-c23ae52288fa","executionInfo":{"status":"ok","timestamp":1668890895302,"user_tz":0,"elapsed":12413922,"user":{"displayName":"jose garcia","userId":"18071348481124640591"}}},"outputs":[{"output_type":"stream","name":"stdout","text":["/content/yolov7\n","YOLOR üöÄ v0.1-115-g072f76c torch 1.12.1+cu113 CUDA:0 (Tesla T4, 15109.75MB)\n","\n","Namespace(adam=False, artifact_alias='latest', batch_size=20, bbox_interval=-1, bucket='', cache_images=False, cfg='', data='/content/yolov7/Weapon-Dataset-2/data.yaml', device='', entity=None, epochs=80, evolve=False, exist_ok=False, freeze=[0], global_rank=-1, hyp='data/hyp.scratch.p5.yaml', image_weights=False, img_size=[640, 640], label_smoothing=0.0, linear_lr=False, local_rank=-1, multi_scale=False, name='exp', noautoanchor=False, nosave=False, notest=False, project='runs/train', quad=False, rect=False, resume=False, save_dir='runs/train/exp2', save_period=-1, single_cls=False, sync_bn=False, total_batch_size=20, upload_dataset=False, v5_metric=False, weights='yolov7_training.pt', workers=8, world_size=1)\n","\u001b[34m\u001b[1mtensorboard: \u001b[0mStart with 'tensorboard --logdir runs/train', view at http://localhost:6006/\n","\u001b[34m\u001b[1mhyperparameters: \u001b[0mlr0=0.01, lrf=0.1, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=0.05, cls=0.3, cls_pw=1.0, obj=0.7, obj_pw=1.0, iou_t=0.2, anchor_t=4.0, fl_gamma=0.0, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.2, scale=0.9, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, mosaic=1.0, mixup=0.15, copy_paste=0.0, paste_in=0.15, loss_ota=1\n","\u001b[34m\u001b[1mwandb\u001b[0m: (1) Create a W&B account\n","\u001b[34m\u001b[1mwandb\u001b[0m: (2) Use an existing W&B account\n","\u001b[34m\u001b[1mwandb\u001b[0m: (3) Don't visualize my results\n","\u001b[34m\u001b[1mwandb\u001b[0m: Enter your choice: 2\n","\u001b[34m\u001b[1mwandb\u001b[0m: You chose 'Use an existing W&B account'\n","\u001b[34m\u001b[1mwandb\u001b[0m: Logging into wandb.ai. (Learn how to deploy a W&B server locally: https://wandb.me/wandb-server)\n","\u001b[34m\u001b[1mwandb\u001b[0m: You can find your API key in your browser here: https://wandb.ai/authorize\n","\u001b[34m\u001b[1mwandb\u001b[0m: Paste an API key from your profile and hit enter, or press ctrl+c to quit: \n","\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: /root/.netrc\n","\u001b[34m\u001b[1mwandb\u001b[0m: Tracking run with wandb version 0.13.5\n","\u001b[34m\u001b[1mwandb\u001b[0m: Run data is saved locally in \u001b[35m\u001b[1m/content/yolov7/wandb/run-20221119_172253-13i0aiif\u001b[0m\n","\u001b[34m\u001b[1mwandb\u001b[0m: Run \u001b[1m`wandb offline`\u001b[0m to turn off syncing.\n","\u001b[34m\u001b[1mwandb\u001b[0m: Syncing run \u001b[33mexp2\u001b[0m\n","\u001b[34m\u001b[1mwandb\u001b[0m: ‚≠êÔ∏è View project at \u001b[34m\u001b[4mhttps://wandb.ai/kra0s22/YOLOR\u001b[0m\n","\u001b[34m\u001b[1mwandb\u001b[0m: üöÄ View run at \u001b[34m\u001b[4mhttps://wandb.ai/kra0s22/YOLOR/runs/13i0aiif\u001b[0m\n","Overriding model.yaml nc=80 with nc=1\n","\n","                 from  n    params  module                                  arguments                     \n","  0                -1  1       928  models.common.Conv                      [3, 32, 3, 1]                 \n","  1                -1  1     18560  models.common.Conv                      [32, 64, 3, 2]                \n","  2                -1  1     36992  models.common.Conv                      [64, 64, 3, 1]                \n","  3                -1  1     73984  models.common.Conv                      [64, 128, 3, 2]               \n","  4                -1  1      8320  models.common.Conv                      [128, 64, 1, 1]               \n","  5                -2  1      8320  models.common.Conv                      [128, 64, 1, 1]               \n","  6                -1  1     36992  models.common.Conv                      [64, 64, 3, 1]                \n","  7                -1  1     36992  models.common.Conv                      [64, 64, 3, 1]                \n","  8                -1  1     36992  models.common.Conv                      [64, 64, 3, 1]                \n","  9                -1  1     36992  models.common.Conv                      [64, 64, 3, 1]                \n"," 10  [-1, -3, -5, -6]  1         0  models.common.Concat                    [1]                           \n"," 11                -1  1     66048  models.common.Conv                      [256, 256, 1, 1]              \n"," 12                -1  1         0  models.common.MP                        []                            \n"," 13                -1  1     33024  models.common.Conv                      [256, 128, 1, 1]              \n"," 14                -3  1     33024  models.common.Conv                      [256, 128, 1, 1]              \n"," 15                -1  1    147712  models.common.Conv                      [128, 128, 3, 2]              \n"," 16          [-1, -3]  1         0  models.common.Concat                    [1]                           \n"," 17                -1  1     33024  models.common.Conv                      [256, 128, 1, 1]              \n"," 18                -2  1     33024  models.common.Conv                      [256, 128, 1, 1]              \n"," 19                -1  1    147712  models.common.Conv                      [128, 128, 3, 1]              \n"," 20                -1  1    147712  models.common.Conv                      [128, 128, 3, 1]              \n"," 21                -1  1    147712  models.common.Conv                      [128, 128, 3, 1]              \n"," 22                -1  1    147712  models.common.Conv                      [128, 128, 3, 1]              \n"," 23  [-1, -3, -5, -6]  1         0  models.common.Concat                    [1]                           \n"," 24                -1  1    263168  models.common.Conv                      [512, 512, 1, 1]              \n"," 25                -1  1         0  models.common.MP                        []                            \n"," 26                -1  1    131584  models.common.Conv                      [512, 256, 1, 1]              \n"," 27                -3  1    131584  models.common.Conv                      [512, 256, 1, 1]              \n"," 28                -1  1    590336  models.common.Conv                      [256, 256, 3, 2]              \n"," 29          [-1, -3]  1         0  models.common.Concat                    [1]                           \n"," 30                -1  1    131584  models.common.Conv                      [512, 256, 1, 1]              \n"," 31                -2  1    131584  models.common.Conv                      [512, 256, 1, 1]              \n"," 32                -1  1    590336  models.common.Conv                      [256, 256, 3, 1]              \n"," 33                -1  1    590336  models.common.Conv                      [256, 256, 3, 1]              \n"," 34                -1  1    590336  models.common.Conv                      [256, 256, 3, 1]              \n"," 35                -1  1    590336  models.common.Conv                      [256, 256, 3, 1]              \n"," 36  [-1, -3, -5, -6]  1         0  models.common.Concat                    [1]                           \n"," 37                -1  1   1050624  models.common.Conv                      [1024, 1024, 1, 1]            \n"," 38                -1  1         0  models.common.MP                        []                            \n"," 39                -1  1    525312  models.common.Conv                      [1024, 512, 1, 1]             \n"," 40                -3  1    525312  models.common.Conv                      [1024, 512, 1, 1]             \n"," 41                -1  1   2360320  models.common.Conv                      [512, 512, 3, 2]              \n"," 42          [-1, -3]  1         0  models.common.Concat                    [1]                           \n"," 43                -1  1    262656  models.common.Conv                      [1024, 256, 1, 1]             \n"," 44                -2  1    262656  models.common.Conv                      [1024, 256, 1, 1]             \n"," 45                -1  1    590336  models.common.Conv                      [256, 256, 3, 1]              \n"," 46                -1  1    590336  models.common.Conv                      [256, 256, 3, 1]              \n"," 47                -1  1    590336  models.common.Conv                      [256, 256, 3, 1]              \n"," 48                -1  1    590336  models.common.Conv                      [256, 256, 3, 1]              \n"," 49  [-1, -3, -5, -6]  1         0  models.common.Concat                    [1]                           \n"," 50                -1  1   1050624  models.common.Conv                      [1024, 1024, 1, 1]            \n"," 51                -1  1   7609344  models.common.SPPCSPC                   [1024, 512, 1]                \n"," 52                -1  1    131584  models.common.Conv                      [512, 256, 1, 1]              \n"," 53                -1  1         0  torch.nn.modules.upsampling.Upsample    [None, 2, 'nearest']          \n"," 54                37  1    262656  models.common.Conv                      [1024, 256, 1, 1]             \n"," 55          [-1, -2]  1         0  models.common.Concat                    [1]                           \n"," 56                -1  1    131584  models.common.Conv                      [512, 256, 1, 1]              \n"," 57                -2  1    131584  models.common.Conv                      [512, 256, 1, 1]              \n"," 58                -1  1    295168  models.common.Conv                      [256, 128, 3, 1]              \n"," 59                -1  1    147712  models.common.Conv                      [128, 128, 3, 1]              \n"," 60                -1  1    147712  models.common.Conv                      [128, 128, 3, 1]              \n"," 61                -1  1    147712  models.common.Conv                      [128, 128, 3, 1]              \n"," 62[-1, -2, -3, -4, -5, -6]  1         0  models.common.Concat                    [1]                           \n"," 63                -1  1    262656  models.common.Conv                      [1024, 256, 1, 1]             \n"," 64                -1  1     33024  models.common.Conv                      [256, 128, 1, 1]              \n"," 65                -1  1         0  torch.nn.modules.upsampling.Upsample    [None, 2, 'nearest']          \n"," 66                24  1     65792  models.common.Conv                      [512, 128, 1, 1]              \n"," 67          [-1, -2]  1         0  models.common.Concat                    [1]                           \n"," 68                -1  1     33024  models.common.Conv                      [256, 128, 1, 1]              \n"," 69                -2  1     33024  models.common.Conv                      [256, 128, 1, 1]              \n"," 70                -1  1     73856  models.common.Conv                      [128, 64, 3, 1]               \n"," 71                -1  1     36992  models.common.Conv                      [64, 64, 3, 1]                \n"," 72                -1  1     36992  models.common.Conv                      [64, 64, 3, 1]                \n"," 73                -1  1     36992  models.common.Conv                      [64, 64, 3, 1]                \n"," 74[-1, -2, -3, -4, -5, -6]  1         0  models.common.Concat                    [1]                           \n"," 75                -1  1     65792  models.common.Conv                      [512, 128, 1, 1]              \n"," 76                -1  1         0  models.common.MP                        []                            \n"," 77                -1  1     16640  models.common.Conv                      [128, 128, 1, 1]              \n"," 78                -3  1     16640  models.common.Conv                      [128, 128, 1, 1]              \n"," 79                -1  1    147712  models.common.Conv                      [128, 128, 3, 2]              \n"," 80      [-1, -3, 63]  1         0  models.common.Concat                    [1]                           \n"," 81                -1  1    131584  models.common.Conv                      [512, 256, 1, 1]              \n"," 82                -2  1    131584  models.common.Conv                      [512, 256, 1, 1]              \n"," 83                -1  1    295168  models.common.Conv                      [256, 128, 3, 1]              \n"," 84                -1  1    147712  models.common.Conv                      [128, 128, 3, 1]              \n"," 85                -1  1    147712  models.common.Conv                      [128, 128, 3, 1]              \n"," 86                -1  1    147712  models.common.Conv                      [128, 128, 3, 1]              \n"," 87[-1, -2, -3, -4, -5, -6]  1         0  models.common.Concat                    [1]                           \n"," 88                -1  1    262656  models.common.Conv                      [1024, 256, 1, 1]             \n"," 89                -1  1         0  models.common.MP                        []                            \n"," 90                -1  1     66048  models.common.Conv                      [256, 256, 1, 1]              \n"," 91                -3  1     66048  models.common.Conv                      [256, 256, 1, 1]              \n"," 92                -1  1    590336  models.common.Conv                      [256, 256, 3, 2]              \n"," 93      [-1, -3, 51]  1         0  models.common.Concat                    [1]                           \n"," 94                -1  1    525312  models.common.Conv                      [1024, 512, 1, 1]             \n"," 95                -2  1    525312  models.common.Conv                      [1024, 512, 1, 1]             \n"," 96                -1  1   1180160  models.common.Conv                      [512, 256, 3, 1]              \n"," 97                -1  1    590336  models.common.Conv                      [256, 256, 3, 1]              \n"," 98                -1  1    590336  models.common.Conv                      [256, 256, 3, 1]              \n"," 99                -1  1    590336  models.common.Conv                      [256, 256, 3, 1]              \n","100[-1, -2, -3, -4, -5, -6]  1         0  models.common.Concat                    [1]                           \n","101                -1  1   1049600  models.common.Conv                      [2048, 512, 1, 1]             \n","102                75  1    328704  models.common.RepConv                   [128, 256, 3, 1]              \n","103                88  1   1312768  models.common.RepConv                   [256, 512, 3, 1]              \n","104               101  1   5246976  models.common.RepConv                   [512, 1024, 3, 1]             \n","105   [102, 103, 104]  1     34156  models.yolo.IDetect                     [1, [[12, 16, 19, 36, 40, 28], [36, 75, 76, 55, 72, 146], [142, 110, 192, 243, 459, 401]], [256, 512, 1024]]\n","/usr/local/lib/python3.7/dist-packages/torch/functional.py:478: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at  ../aten/src/ATen/native/TensorShape.cpp:2894.)\n","  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]\n","Model Summary: 415 layers, 37196556 parameters, 37196556 gradients, 105.1 GFLOPS\n","\n","Transferred 557/566 items from yolov7_training.pt\n","Scaled weight_decay = 0.00046875\n","Optimizer groups: 95 .bias, 95 conv.weight, 98 other\n","\u001b[34m\u001b[1mtrain: \u001b[0mScanning 'Weapon-Dataset-2/train/labels.cache' images and labels... 2708 found, 0 missing, 0 empty, 0 corrupted: 100% 2708/2708 [00:00<?, ?it/s]\n","\u001b[34m\u001b[1mval: \u001b[0mScanning 'Weapon-Dataset-2/valid/labels.cache' images and labels... 775 found, 0 missing, 0 empty, 0 corrupted: 100% 775/775 [00:00<?, ?it/s]\n","\n","\u001b[34m\u001b[1mautoanchor: \u001b[0mAnalyzing anchors... anchors/target = 3.52, Best Possible Recall (BPR) = 1.0000\n","Image sizes 640 train, 640 test\n","Using 2 dataloader workers\n","Logging results to runs/train/exp2\n","Starting training for 80 epochs...\n","\n","     Epoch   gpu_mem       box       obj       cls     total    labels  img_size\n","      0/79     8.29G   0.06245   0.01313         0   0.07558        33       640: 100% 136/136 [02:56<00:00,  1.30s/it]\n","               Class      Images      Labels           P           R      mAP@.5  mAP@.5:.95: 100% 20/20 [00:25<00:00,  1.30s/it]\n","                 all         775         886        0.36        0.42       0.347       0.144\n","\n","     Epoch   gpu_mem       box       obj       cls     total    labels  img_size\n","      1/79     13.7G   0.05804   0.01012         0   0.06817        20       640: 100% 136/136 [02:26<00:00,  1.08s/it]\n","               Class      Images      Labels           P           R      mAP@.5  mAP@.5:.95: 100% 20/20 [00:14<00:00,  1.33it/s]\n","                 all         775         886       0.396       0.389        0.34       0.152\n","\n","     Epoch   gpu_mem       box       obj       cls     total    labels  img_size\n","      2/79     13.7G   0.05678  0.009755         0   0.06654        20       640: 100% 136/136 [02:24<00:00,  1.06s/it]\n","               Class      Images      Labels           P           R      mAP@.5  mAP@.5:.95: 100% 20/20 [00:13<00:00,  1.50it/s]\n","                 all         775         886       0.411       0.407       0.325       0.155\n","\n","     Epoch   gpu_mem       box       obj       cls     total    labels  img_size\n","      3/79     13.7G      0.06   0.01008         0   0.07008        41       640: 100% 136/136 [02:20<00:00,  1.03s/it]\n","               Class      Images      Labels           P           R      mAP@.5  mAP@.5:.95: 100% 20/20 [00:14<00:00,  1.40it/s]\n","                 all         775         886       0.167        0.35       0.105      0.0476\n","\n","     Epoch   gpu_mem       box       obj       cls     total    labels  img_size\n","      4/79     13.7G   0.05981  0.009641         0   0.06945        29       640: 100% 136/136 [02:22<00:00,  1.05s/it]\n","               Class      Images      Labels           P           R      mAP@.5  mAP@.5:.95: 100% 20/20 [00:13<00:00,  1.48it/s]\n","                 all         775         886      0.0178      0.0282     0.00403    0.000853\n","\n","     Epoch   gpu_mem       box       obj       cls     total    labels  img_size\n","      5/79     13.7G   0.06129  0.009834         0   0.07113        13       640: 100% 136/136 [02:22<00:00,  1.05s/it]\n","               Class      Images      Labels           P           R      mAP@.5  mAP@.5:.95: 100% 20/20 [00:13<00:00,  1.49it/s]\n","                 all         775         886       0.182       0.266       0.108      0.0327\n","\n","     Epoch   gpu_mem       box       obj       cls     total    labels  img_size\n","      6/79     13.7G   0.06091  0.009895         0   0.07081        30       640: 100% 136/136 [02:23<00:00,  1.05s/it]\n","               Class      Images      Labels           P           R      mAP@.5  mAP@.5:.95: 100% 20/20 [00:13<00:00,  1.50it/s]\n","                 all         775         886       0.313       0.356       0.227        0.09\n","\n","     Epoch   gpu_mem       box       obj       cls     total    labels  img_size\n","      7/79     13.7G    0.0588  0.009556         0   0.06836        17       640: 100% 136/136 [02:19<00:00,  1.02s/it]\n","               Class      Images      Labels           P           R      mAP@.5  mAP@.5:.95: 100% 20/20 [00:16<00:00,  1.24it/s]\n","                 all         775         886       0.306       0.328       0.211      0.0847\n","\n","     Epoch   gpu_mem       box       obj       cls     total    labels  img_size\n","      8/79     13.7G   0.05699  0.009793         0   0.06678        21       640: 100% 136/136 [02:20<00:00,  1.03s/it]\n","               Class      Images      Labels           P           R      mAP@.5  mAP@.5:.95: 100% 20/20 [00:13<00:00,  1.49it/s]\n","                 all         775         886       0.232       0.422       0.202      0.0712\n","\n","     Epoch   gpu_mem       box       obj       cls     total    labels  img_size\n","      9/79     13.7G   0.05662  0.009501         0   0.06612        14       640: 100% 136/136 [02:21<00:00,  1.04s/it]\n","               Class      Images      Labels           P           R      mAP@.5  mAP@.5:.95: 100% 20/20 [00:13<00:00,  1.44it/s]\n","                 all         775         886       0.246       0.388       0.219      0.0943\n","\n","     Epoch   gpu_mem       box       obj       cls     total    labels  img_size\n","     10/79     13.7G   0.05438   0.00934         0   0.06372        32       640: 100% 136/136 [02:21<00:00,  1.04s/it]\n","               Class      Images      Labels           P           R      mAP@.5  mAP@.5:.95: 100% 20/20 [00:15<00:00,  1.31it/s]\n","                 all         775         886       0.557       0.442       0.464       0.256\n","\n","     Epoch   gpu_mem       box       obj       cls     total    labels  img_size\n","     11/79     13.7G   0.05535  0.009325         0   0.06467        23       640: 100% 136/136 [02:27<00:00,  1.08s/it]\n","               Class      Images      Labels           P           R      mAP@.5  mAP@.5:.95: 100% 20/20 [00:13<00:00,  1.49it/s]\n","                 all         775         886       0.401       0.354       0.302       0.133\n","\n","     Epoch   gpu_mem       box       obj       cls     total    labels  img_size\n","     12/79     13.7G   0.05338  0.009396         0   0.06278        26       640: 100% 136/136 [02:22<00:00,  1.05s/it]\n","               Class      Images      Labels           P           R      mAP@.5  mAP@.5:.95: 100% 20/20 [00:13<00:00,  1.51it/s]\n","                 all         775         886       0.593       0.432       0.456       0.222\n","\n","     Epoch   gpu_mem       box       obj       cls     total    labels  img_size\n","     13/79     13.7G    0.0537  0.009133         0   0.06284        13       640: 100% 136/136 [02:23<00:00,  1.06s/it]\n","               Class      Images      Labels           P           R      mAP@.5  mAP@.5:.95: 100% 20/20 [00:14<00:00,  1.40it/s]\n","                 all         775         886       0.572       0.468        0.49       0.272\n","\n","     Epoch   gpu_mem       box       obj       cls     total    labels  img_size\n","     14/79     13.7G   0.05274  0.009221         0   0.06196        31       640: 100% 136/136 [02:21<00:00,  1.04s/it]\n","               Class      Images      Labels           P           R      mAP@.5  mAP@.5:.95: 100% 20/20 [00:13<00:00,  1.50it/s]\n","                 all         775         886       0.596       0.453       0.473       0.257\n","\n","     Epoch   gpu_mem       box       obj       cls     total    labels  img_size\n","     15/79     13.7G   0.05253  0.009335         0   0.06186        22       640: 100% 136/136 [02:21<00:00,  1.04s/it]\n","               Class      Images      Labels           P           R      mAP@.5  mAP@.5:.95: 100% 20/20 [00:14<00:00,  1.35it/s]\n","                 all         775         886        0.42        0.47       0.415       0.218\n","\n","     Epoch   gpu_mem       box       obj       cls     total    labels  img_size\n","     16/79     13.7G   0.05165  0.009167         0   0.06082        23       640: 100% 136/136 [02:20<00:00,  1.04s/it]\n","               Class      Images      Labels           P           R      mAP@.5  mAP@.5:.95: 100% 20/20 [00:14<00:00,  1.43it/s]\n","                 all         775         886       0.664       0.495       0.555       0.337\n","\n","     Epoch   gpu_mem       box       obj       cls     total    labels  img_size\n","     17/79     13.7G   0.05179  0.009112         0    0.0609        21       640: 100% 136/136 [02:19<00:00,  1.03s/it]\n","               Class      Images      Labels           P           R      mAP@.5  mAP@.5:.95: 100% 20/20 [00:13<00:00,  1.50it/s]\n","                 all         775         886       0.693       0.359       0.462       0.277\n","\n","     Epoch   gpu_mem       box       obj       cls     total    labels  img_size\n","     18/79     13.7G   0.05192  0.009074         0     0.061        17       640: 100% 136/136 [02:17<00:00,  1.01s/it]\n","               Class      Images      Labels           P           R      mAP@.5  mAP@.5:.95: 100% 20/20 [00:13<00:00,  1.51it/s]\n","                 all         775         886       0.675       0.501       0.574        0.35\n","\n","     Epoch   gpu_mem       box       obj       cls     total    labels  img_size\n","     19/79     13.7G   0.05056  0.008869         0   0.05943        21       640: 100% 136/136 [02:16<00:00,  1.00s/it]\n","               Class      Images      Labels           P           R      mAP@.5  mAP@.5:.95: 100% 20/20 [00:13<00:00,  1.50it/s]\n","                 all         775         886       0.664       0.493       0.555       0.322\n","\n","     Epoch   gpu_mem       box       obj       cls     total    labels  img_size\n","     20/79     13.7G   0.05038  0.008832         0   0.05921        23       640: 100% 136/136 [02:16<00:00,  1.00s/it]\n","               Class      Images      Labels           P           R      mAP@.5  mAP@.5:.95: 100% 20/20 [00:13<00:00,  1.50it/s]\n","                 all         775         886       0.534        0.41        0.45       0.235\n","\n","     Epoch   gpu_mem       box       obj       cls     total    labels  img_size\n","     21/79     13.7G   0.05107   0.00914         0   0.06021        24       640: 100% 136/136 [02:17<00:00,  1.01s/it]\n","               Class      Images      Labels           P           R      mAP@.5  mAP@.5:.95: 100% 20/20 [00:13<00:00,  1.49it/s]\n","                 all         775         886       0.711       0.484       0.566       0.348\n","\n","     Epoch   gpu_mem       box       obj       cls     total    labels  img_size\n","     22/79     13.7G   0.05112  0.008757         0   0.05987        22       640: 100% 136/136 [02:13<00:00,  1.02it/s]\n","               Class      Images      Labels           P           R      mAP@.5  mAP@.5:.95: 100% 20/20 [00:13<00:00,  1.49it/s]\n","                 all         775         886       0.545       0.448       0.476       0.288\n","\n","     Epoch   gpu_mem       box       obj       cls     total    labels  img_size\n","     23/79     13.7G   0.04848  0.009063         0   0.05755        17       640: 100% 136/136 [02:16<00:00,  1.00s/it]\n","               Class      Images      Labels           P           R      mAP@.5  mAP@.5:.95: 100% 20/20 [00:14<00:00,  1.34it/s]\n","                 all         775         886       0.556       0.487       0.491       0.278\n","\n","     Epoch   gpu_mem       box       obj       cls     total    labels  img_size\n","     24/79     13.7G   0.04871  0.008917         0   0.05762        28       640: 100% 136/136 [02:17<00:00,  1.01s/it]\n","               Class      Images      Labels           P           R      mAP@.5  mAP@.5:.95: 100% 20/20 [00:13<00:00,  1.50it/s]\n","                 all         775         886       0.657        0.52       0.591       0.354\n","\n","     Epoch   gpu_mem       box       obj       cls     total    labels  img_size\n","     25/79     13.7G   0.04956  0.008942         0    0.0585        21       640: 100% 136/136 [02:16<00:00,  1.00s/it]\n","               Class      Images      Labels           P           R      mAP@.5  mAP@.5:.95: 100% 20/20 [00:13<00:00,  1.50it/s]\n","                 all         775         886       0.698       0.542       0.608       0.369\n","\n","     Epoch   gpu_mem       box       obj       cls     total    labels  img_size\n","     26/79     13.7G   0.05011  0.008923         0   0.05904        19       640: 100% 136/136 [02:17<00:00,  1.01s/it]\n","               Class      Images      Labels           P           R      mAP@.5  mAP@.5:.95: 100% 20/20 [00:13<00:00,  1.51it/s]\n","                 all         775         886       0.703       0.553       0.618       0.371\n","\n","     Epoch   gpu_mem       box       obj       cls     total    labels  img_size\n","     27/79     13.7G   0.04911  0.008701         0   0.05781        17       640: 100% 136/136 [02:15<00:00,  1.01it/s]\n","               Class      Images      Labels           P           R      mAP@.5  mAP@.5:.95: 100% 20/20 [00:14<00:00,  1.41it/s]\n","                 all         775         886        0.67       0.558       0.602       0.355\n","\n","     Epoch   gpu_mem       box       obj       cls     total    labels  img_size\n","     28/79     13.7G   0.04891  0.008843         0   0.05775        35       640: 100% 136/136 [02:14<00:00,  1.01it/s]\n","               Class      Images      Labels           P           R      mAP@.5  mAP@.5:.95: 100% 20/20 [00:13<00:00,  1.51it/s]\n","                 all         775         886       0.697       0.525       0.608       0.384\n","\n","     Epoch   gpu_mem       box       obj       cls     total    labels  img_size\n","     29/79     13.7G   0.05017  0.008712         0   0.05888        21       640: 100% 136/136 [02:17<00:00,  1.01s/it]\n","               Class      Images      Labels           P           R      mAP@.5  mAP@.5:.95: 100% 20/20 [00:13<00:00,  1.51it/s]\n","                 all         775         886       0.646       0.534        0.56       0.336\n","\n","     Epoch   gpu_mem       box       obj       cls     total    labels  img_size\n","     30/79     13.7G   0.04908  0.008688         0   0.05777        27       640: 100% 136/136 [02:17<00:00,  1.01s/it]\n","               Class      Images      Labels           P           R      mAP@.5  mAP@.5:.95: 100% 20/20 [00:13<00:00,  1.51it/s]\n","                 all         775         886       0.678       0.572       0.627       0.369\n","\n","     Epoch   gpu_mem       box       obj       cls     total    labels  img_size\n","     31/79     13.7G   0.04917   0.00877         0   0.05794        34       640: 100% 136/136 [02:17<00:00,  1.01s/it]\n","               Class      Images      Labels           P           R      mAP@.5  mAP@.5:.95: 100% 20/20 [00:14<00:00,  1.35it/s]\n","                 all         775         886         0.7       0.559        0.64       0.403\n","\n","     Epoch   gpu_mem       box       obj       cls     total    labels  img_size\n","     32/79     13.7G   0.04895  0.008545         0    0.0575        27       640: 100% 136/136 [02:16<00:00,  1.01s/it]\n","               Class      Images      Labels           P           R      mAP@.5  mAP@.5:.95: 100% 20/20 [00:13<00:00,  1.50it/s]\n","                 all         775         886       0.757        0.54       0.651       0.405\n","\n","     Epoch   gpu_mem       box       obj       cls     total    labels  img_size\n","     33/79     13.7G   0.04746  0.008612         0   0.05607        15       640: 100% 136/136 [02:14<00:00,  1.01it/s]\n","               Class      Images      Labels           P           R      mAP@.5  mAP@.5:.95: 100% 20/20 [00:13<00:00,  1.52it/s]\n","                 all         775         886       0.687       0.559       0.631       0.399\n","\n","     Epoch   gpu_mem       box       obj       cls     total    labels  img_size\n","     34/79     13.7G   0.04744    0.0086         0   0.05604        32       640: 100% 136/136 [02:18<00:00,  1.02s/it]\n","               Class      Images      Labels           P           R      mAP@.5  mAP@.5:.95: 100% 20/20 [00:13<00:00,  1.50it/s]\n","                 all         775         886       0.663       0.563       0.628       0.395\n","\n","     Epoch   gpu_mem       box       obj       cls     total    labels  img_size\n","     35/79     13.7G   0.04906  0.008501         0   0.05756        13       640: 100% 136/136 [02:17<00:00,  1.01s/it]\n","               Class      Images      Labels           P           R      mAP@.5  mAP@.5:.95: 100% 20/20 [00:13<00:00,  1.51it/s]\n","                 all         775         886       0.675       0.559       0.638       0.399\n","\n","     Epoch   gpu_mem       box       obj       cls     total    labels  img_size\n","     36/79     13.7G   0.04523  0.008329         0   0.05356        19       640: 100% 136/136 [02:14<00:00,  1.01it/s]\n","               Class      Images      Labels           P           R      mAP@.5  mAP@.5:.95: 100% 20/20 [00:13<00:00,  1.51it/s]\n","                 all         775         886       0.673       0.577       0.647       0.394\n","\n","     Epoch   gpu_mem       box       obj       cls     total    labels  img_size\n","     37/79     13.7G   0.04592  0.008432         0   0.05435        29       640: 100% 136/136 [02:18<00:00,  1.02s/it]\n","               Class      Images      Labels           P           R      mAP@.5  mAP@.5:.95: 100% 20/20 [00:13<00:00,  1.51it/s]\n","                 all         775         886       0.777       0.597         0.7       0.444\n","\n","     Epoch   gpu_mem       box       obj       cls     total    labels  img_size\n","     38/79     13.7G   0.04479  0.008563         0   0.05335        26       640: 100% 136/136 [02:14<00:00,  1.01it/s]\n","               Class      Images      Labels           P           R      mAP@.5  mAP@.5:.95: 100% 20/20 [00:13<00:00,  1.50it/s]\n","                 all         775         886       0.715       0.647       0.701       0.457\n","\n","     Epoch   gpu_mem       box       obj       cls     total    labels  img_size\n","     39/79     13.7G   0.04656  0.008362         0   0.05492        30       640: 100% 136/136 [02:17<00:00,  1.01s/it]\n","               Class      Images      Labels           P           R      mAP@.5  mAP@.5:.95: 100% 20/20 [00:14<00:00,  1.37it/s]\n","                 all         775         886       0.714       0.602       0.687       0.445\n","\n","     Epoch   gpu_mem       box       obj       cls     total    labels  img_size\n","     40/79     13.7G   0.04742  0.008489         0   0.05591        18       640: 100% 136/136 [02:18<00:00,  1.02s/it]\n","               Class      Images      Labels           P           R      mAP@.5  mAP@.5:.95: 100% 20/20 [00:13<00:00,  1.51it/s]\n","                 all         775         886       0.778       0.569       0.673       0.434\n","\n","     Epoch   gpu_mem       box       obj       cls     total    labels  img_size\n","     41/79     13.7G   0.04636  0.008455         0   0.05482        18       640: 100% 136/136 [02:13<00:00,  1.02it/s]\n","               Class      Images      Labels           P           R      mAP@.5  mAP@.5:.95: 100% 20/20 [00:13<00:00,  1.51it/s]\n","                 all         775         886       0.711       0.621       0.678       0.428\n","\n","     Epoch   gpu_mem       box       obj       cls     total    labels  img_size\n","     42/79     13.7G   0.04608  0.008428         0    0.0545        16       640: 100% 136/136 [02:17<00:00,  1.01s/it]\n","               Class      Images      Labels           P           R      mAP@.5  mAP@.5:.95: 100% 20/20 [00:13<00:00,  1.50it/s]\n","                 all         775         886       0.742       0.624       0.708       0.455\n","\n","     Epoch   gpu_mem       box       obj       cls     total    labels  img_size\n","     43/79     13.7G   0.04606  0.008459         0   0.05452        26       640: 100% 136/136 [02:14<00:00,  1.01it/s]\n","               Class      Images      Labels           P           R      mAP@.5  mAP@.5:.95: 100% 20/20 [00:13<00:00,  1.51it/s]\n","                 all         775         886       0.798       0.594       0.715       0.467\n","\n","     Epoch   gpu_mem       box       obj       cls     total    labels  img_size\n","     44/79     13.7G   0.04402   0.00851         0   0.05253        16       640: 100% 136/136 [02:17<00:00,  1.01s/it]\n","               Class      Images      Labels           P           R      mAP@.5  mAP@.5:.95: 100% 20/20 [00:13<00:00,  1.51it/s]\n","                 all         775         886       0.735       0.637       0.724        0.46\n","\n","     Epoch   gpu_mem       box       obj       cls     total    labels  img_size\n","     45/79     13.7G   0.04389  0.008176         0   0.05206        21       640: 100% 136/136 [02:15<00:00,  1.00it/s]\n","               Class      Images      Labels           P           R      mAP@.5  mAP@.5:.95: 100% 20/20 [00:14<00:00,  1.40it/s]\n","                 all         775         886       0.715        0.64       0.709       0.464\n","\n","     Epoch   gpu_mem       box       obj       cls     total    labels  img_size\n","     46/79     13.7G   0.04506  0.008232         0   0.05329        22       640: 100% 136/136 [02:14<00:00,  1.01it/s]\n","               Class      Images      Labels           P           R      mAP@.5  mAP@.5:.95: 100% 20/20 [00:13<00:00,  1.50it/s]\n","                 all         775         886       0.727        0.65       0.723       0.464\n","\n","     Epoch   gpu_mem       box       obj       cls     total    labels  img_size\n","     47/79     13.7G    0.0448  0.008278         0   0.05308        28       640: 100% 136/136 [02:16<00:00,  1.01s/it]\n","               Class      Images      Labels           P           R      mAP@.5  mAP@.5:.95: 100% 20/20 [00:14<00:00,  1.35it/s]\n","                 all         775         886       0.767       0.644       0.733       0.468\n","\n","     Epoch   gpu_mem       box       obj       cls     total    labels  img_size\n","     48/79     13.7G   0.04538  0.008249         0   0.05363        24       640: 100% 136/136 [02:13<00:00,  1.02it/s]\n","               Class      Images      Labels           P           R      mAP@.5  mAP@.5:.95: 100% 20/20 [00:13<00:00,  1.51it/s]\n","                 all         775         886       0.812        0.59       0.712       0.465\n","\n","     Epoch   gpu_mem       box       obj       cls     total    labels  img_size\n","     49/79     13.7G   0.04445  0.008464         0   0.05291        27       640: 100% 136/136 [02:17<00:00,  1.01s/it]\n","               Class      Images      Labels           P           R      mAP@.5  mAP@.5:.95: 100% 20/20 [00:13<00:00,  1.51it/s]\n","                 all         775         886       0.765       0.657       0.735       0.486\n","\n","     Epoch   gpu_mem       box       obj       cls     total    labels  img_size\n","     50/79     13.7G   0.04367  0.008059         0   0.05172        30       640: 100% 136/136 [02:16<00:00,  1.01s/it]\n","               Class      Images      Labels           P           R      mAP@.5  mAP@.5:.95: 100% 20/20 [00:13<00:00,  1.50it/s]\n","                 all         775         886       0.785       0.665       0.739       0.483\n","\n","     Epoch   gpu_mem       box       obj       cls     total    labels  img_size\n","     51/79     13.7G   0.04327  0.007996         0   0.05127        19       640: 100% 136/136 [02:13<00:00,  1.02it/s]\n","               Class      Images      Labels           P           R      mAP@.5  mAP@.5:.95: 100% 20/20 [00:13<00:00,  1.51it/s]\n","                 all         775         886       0.737       0.685       0.739       0.491\n","\n","     Epoch   gpu_mem       box       obj       cls     total    labels  img_size\n","     52/79     13.7G   0.04374  0.008061         0    0.0518        13       640: 100% 136/136 [02:16<00:00,  1.00s/it]\n","               Class      Images      Labels           P           R      mAP@.5  mAP@.5:.95: 100% 20/20 [00:13<00:00,  1.51it/s]\n","                 all         775         886       0.746       0.663       0.736       0.489\n","\n","     Epoch   gpu_mem       box       obj       cls     total    labels  img_size\n","     53/79     13.7G   0.04287  0.008137         0   0.05101        25       640: 100% 136/136 [02:13<00:00,  1.02it/s]\n","               Class      Images      Labels           P           R      mAP@.5  mAP@.5:.95: 100% 20/20 [00:13<00:00,  1.51it/s]\n","                 all         775         886       0.813       0.628       0.745       0.497\n","\n","     Epoch   gpu_mem       box       obj       cls     total    labels  img_size\n","     54/79     13.7G   0.04297  0.008188         0   0.05116        24       640: 100% 136/136 [02:17<00:00,  1.01s/it]\n","               Class      Images      Labels           P           R      mAP@.5  mAP@.5:.95: 100% 20/20 [00:13<00:00,  1.51it/s]\n","                 all         775         886       0.799       0.655       0.745       0.496\n","\n","     Epoch   gpu_mem       box       obj       cls     total    labels  img_size\n","     55/79     13.7G   0.04236  0.008141         0    0.0505        20       640: 100% 136/136 [02:17<00:00,  1.01s/it]\n","               Class      Images      Labels           P           R      mAP@.5  mAP@.5:.95: 100% 20/20 [00:14<00:00,  1.36it/s]\n","                 all         775         886       0.782       0.676       0.757       0.499\n","\n","     Epoch   gpu_mem       box       obj       cls     total    labels  img_size\n","     56/79     13.7G   0.04099  0.008188         0   0.04918        25       640: 100% 136/136 [02:13<00:00,  1.02it/s]\n","               Class      Images      Labels           P           R      mAP@.5  mAP@.5:.95: 100% 20/20 [00:13<00:00,  1.51it/s]\n","                 all         775         886       0.804       0.652       0.756       0.502\n","\n","     Epoch   gpu_mem       box       obj       cls     total    labels  img_size\n","     57/79     13.7G   0.04125  0.008007         0   0.04926        23       640: 100% 136/136 [02:16<00:00,  1.01s/it]\n","               Class      Images      Labels           P           R      mAP@.5  mAP@.5:.95: 100% 20/20 [00:13<00:00,  1.51it/s]\n","                 all         775         886       0.872       0.632        0.77        0.52\n","\n","     Epoch   gpu_mem       box       obj       cls     total    labels  img_size\n","     58/79     13.7G   0.04083  0.008105         0   0.04894        17       640: 100% 136/136 [02:14<00:00,  1.01it/s]\n","               Class      Images      Labels           P           R      mAP@.5  mAP@.5:.95: 100% 20/20 [00:15<00:00,  1.32it/s]\n","                 all         775         886       0.785       0.694       0.764       0.517\n","\n","     Epoch   gpu_mem       box       obj       cls     total    labels  img_size\n","     59/79     13.7G   0.04055  0.007851         0    0.0484        19       640: 100% 136/136 [02:14<00:00,  1.01it/s]\n","               Class      Images      Labels           P           R      mAP@.5  mAP@.5:.95: 100% 20/20 [00:13<00:00,  1.51it/s]\n","                 all         775         886       0.789       0.693       0.773       0.519\n","\n","     Epoch   gpu_mem       box       obj       cls     total    labels  img_size\n","     60/79     13.7G   0.03979  0.007965         0   0.04776        19       640: 100% 136/136 [02:16<00:00,  1.01s/it]\n","               Class      Images      Labels           P           R      mAP@.5  mAP@.5:.95: 100% 20/20 [00:13<00:00,  1.51it/s]\n","                 all         775         886       0.796       0.672       0.761        0.52\n","\n","     Epoch   gpu_mem       box       obj       cls     total    labels  img_size\n","     61/79     13.7G   0.04165  0.007818         0   0.04947        12       640: 100% 136/136 [02:14<00:00,  1.01it/s]\n","               Class      Images      Labels           P           R      mAP@.5  mAP@.5:.95: 100% 20/20 [00:13<00:00,  1.51it/s]\n","                 all         775         886         0.8       0.659       0.758       0.513\n","\n","     Epoch   gpu_mem       box       obj       cls     total    labels  img_size\n","     62/79     13.7G   0.03989  0.008041         0   0.04793        28       640: 100% 136/136 [02:17<00:00,  1.01s/it]\n","               Class      Images      Labels           P           R      mAP@.5  mAP@.5:.95: 100% 20/20 [00:13<00:00,  1.51it/s]\n","                 all         775         886       0.844       0.665       0.771       0.528\n","\n","     Epoch   gpu_mem       box       obj       cls     total    labels  img_size\n","     63/79     13.7G   0.04133  0.007899         0   0.04923        19       640: 100% 136/136 [02:17<00:00,  1.01s/it]\n","               Class      Images      Labels           P           R      mAP@.5  mAP@.5:.95: 100% 20/20 [00:14<00:00,  1.36it/s]\n","                 all         775         886       0.824       0.676        0.78       0.531\n","\n","     Epoch   gpu_mem       box       obj       cls     total    labels  img_size\n","     64/79     13.7G   0.04033   0.00805         0   0.04838        22       640: 100% 136/136 [02:14<00:00,  1.01it/s]\n","               Class      Images      Labels           P           R      mAP@.5  mAP@.5:.95: 100% 20/20 [00:13<00:00,  1.50it/s]\n","                 all         775         886       0.815       0.686       0.777       0.523\n","\n","     Epoch   gpu_mem       box       obj       cls     total    labels  img_size\n","     65/79     13.7G   0.03877  0.007789         0   0.04656        26       640: 100% 136/136 [02:18<00:00,  1.02s/it]\n","               Class      Images      Labels           P           R      mAP@.5  mAP@.5:.95: 100% 20/20 [00:13<00:00,  1.50it/s]\n","                 all         775         886       0.846        0.68       0.786       0.536\n","\n","     Epoch   gpu_mem       box       obj       cls     total    labels  img_size\n","     66/79     13.7G   0.03831  0.007886         0   0.04619        29       640: 100% 136/136 [02:17<00:00,  1.01s/it]\n","               Class      Images      Labels           P           R      mAP@.5  mAP@.5:.95: 100% 20/20 [00:13<00:00,  1.52it/s]\n","                 all         775         886       0.851       0.684       0.792       0.542\n","\n","     Epoch   gpu_mem       box       obj       cls     total    labels  img_size\n","     67/79     13.7G   0.03971  0.007914         0   0.04762        38       640: 100% 136/136 [02:13<00:00,  1.02it/s]\n","               Class      Images      Labels           P           R      mAP@.5  mAP@.5:.95: 100% 20/20 [00:13<00:00,  1.51it/s]\n","                 all         775         886       0.825       0.666       0.779       0.531\n","\n","     Epoch   gpu_mem       box       obj       cls     total    labels  img_size\n","     68/79     13.7G   0.04014  0.007781         0   0.04792        32       640: 100% 136/136 [02:16<00:00,  1.01s/it]\n","               Class      Images      Labels           P           R      mAP@.5  mAP@.5:.95: 100% 20/20 [00:13<00:00,  1.50it/s]\n","                 all         775         886       0.839       0.708       0.799       0.545\n","\n","     Epoch   gpu_mem       box       obj       cls     total    labels  img_size\n","     69/79     13.7G   0.04001  0.008022         0   0.04803        22       640: 100% 136/136 [02:15<00:00,  1.01it/s]\n","               Class      Images      Labels           P           R      mAP@.5  mAP@.5:.95: 100% 20/20 [00:13<00:00,  1.51it/s]\n","                 all         775         886        0.81       0.716       0.799       0.544\n","\n","     Epoch   gpu_mem       box       obj       cls     total    labels  img_size\n","     70/79     13.7G   0.03858  0.007899         0   0.04648        21       640: 100% 136/136 [02:14<00:00,  1.01it/s]\n","               Class      Images      Labels           P           R      mAP@.5  mAP@.5:.95: 100% 20/20 [00:13<00:00,  1.45it/s]\n","                 all         775         886       0.803       0.731       0.803        0.55\n","\n","     Epoch   gpu_mem       box       obj       cls     total    labels  img_size\n","     71/79     13.7G   0.03959  0.007708         0    0.0473        22       640: 100% 136/136 [02:13<00:00,  1.02it/s]\n","               Class      Images      Labels           P           R      mAP@.5  mAP@.5:.95: 100% 20/20 [00:14<00:00,  1.37it/s]\n","                 all         775         886       0.809       0.718       0.793       0.546\n","\n","     Epoch   gpu_mem       box       obj       cls     total    labels  img_size\n","     72/79     13.7G   0.03919  0.007838         0   0.04703        25       640: 100% 136/136 [02:16<00:00,  1.00s/it]\n","               Class      Images      Labels           P           R      mAP@.5  mAP@.5:.95: 100% 20/20 [00:13<00:00,  1.51it/s]\n","                 all         775         886       0.845       0.694       0.797       0.546\n","\n","     Epoch   gpu_mem       box       obj       cls     total    labels  img_size\n","     73/79     13.7G   0.03976  0.007796         0   0.04755        20       640: 100% 136/136 [02:15<00:00,  1.00it/s]\n","               Class      Images      Labels           P           R      mAP@.5  mAP@.5:.95: 100% 20/20 [00:13<00:00,  1.51it/s]\n","                 all         775         886       0.821       0.714       0.799       0.553\n","\n","     Epoch   gpu_mem       box       obj       cls     total    labels  img_size\n","     74/79     13.7G   0.03749  0.007828         0   0.04532        18       640: 100% 136/136 [02:15<00:00,  1.00it/s]\n","               Class      Images      Labels           P           R      mAP@.5  mAP@.5:.95: 100% 20/20 [00:13<00:00,  1.51it/s]\n","                 all         775         886       0.845       0.714       0.804       0.559\n","\n","     Epoch   gpu_mem       box       obj       cls     total    labels  img_size\n","     75/79     13.7G   0.03875  0.007601         0   0.04635        22       640: 100% 136/136 [02:15<00:00,  1.00it/s]\n","               Class      Images      Labels           P           R      mAP@.5  mAP@.5:.95: 100% 20/20 [00:13<00:00,  1.51it/s]\n","                 all         775         886       0.844       0.707       0.801       0.554\n","\n","     Epoch   gpu_mem       box       obj       cls     total    labels  img_size\n","     76/79     13.7G   0.03844  0.007665         0   0.04611        28       640: 100% 136/136 [02:15<00:00,  1.00it/s]\n","               Class      Images      Labels           P           R      mAP@.5  mAP@.5:.95: 100% 20/20 [00:13<00:00,  1.51it/s]\n","                 all         775         886       0.845       0.707       0.807       0.556\n","\n","     Epoch   gpu_mem       box       obj       cls     total    labels  img_size\n","     77/79     13.7G   0.03839  0.007925         0   0.04631        30       640: 100% 136/136 [02:15<00:00,  1.00it/s]\n","               Class      Images      Labels           P           R      mAP@.5  mAP@.5:.95: 100% 20/20 [00:13<00:00,  1.51it/s]\n","                 all         775         886       0.845       0.712       0.807       0.557\n","\n","     Epoch   gpu_mem       box       obj       cls     total    labels  img_size\n","     78/79     13.7G    0.0384  0.007567         0   0.04597        20       640: 100% 136/136 [02:15<00:00,  1.00it/s]\n","               Class      Images      Labels           P           R      mAP@.5  mAP@.5:.95: 100% 20/20 [00:13<00:00,  1.51it/s]\n","                 all         775         886       0.829        0.72       0.806       0.554\n","\n","     Epoch   gpu_mem       box       obj       cls     total    labels  img_size\n","     79/79     13.7G   0.03748  0.007579         0   0.04506        19       640: 100% 136/136 [02:15<00:00,  1.00it/s]\n","               Class      Images      Labels           P           R      mAP@.5  mAP@.5:.95: 100% 20/20 [00:16<00:00,  1.21it/s]\n","                 all         775         886       0.838       0.725       0.804       0.559\n","80 epochs completed in 3.416 hours.\n","\n","Optimizer stripped from runs/train/exp2/weights/last.pt, 74.8MB\n","Optimizer stripped from runs/train/exp2/weights/best.pt, 74.8MB\n","Images sizes do not match. This will causes images to be display incorrectly in the UI.\n","\u001b[34m\u001b[1mwandb\u001b[0m: Waiting for W&B process to finish... \u001b[32m(success).\u001b[0m\n","\u001b[34m\u001b[1mwandb\u001b[0m: \n","\u001b[34m\u001b[1mwandb\u001b[0m: Run history:\n","\u001b[34m\u001b[1mwandb\u001b[0m:      metrics/mAP_0.5 ‚ñÑ‚ñÑ‚ñÅ‚ñÉ‚ñÉ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà\n","\u001b[34m\u001b[1mwandb\u001b[0m: metrics/mAP_0.5:0.95 ‚ñÉ‚ñÉ‚ñÅ‚ñÇ‚ñÇ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÑ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà\n","\u001b[34m\u001b[1mwandb\u001b[0m:    metrics/precision ‚ñÑ‚ñÑ‚ñÅ‚ñÉ‚ñÉ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñÖ‚ñÖ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñá‚ñá‚ñà‚ñà‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà\n","\u001b[34m\u001b[1mwandb\u001b[0m:       metrics/recall ‚ñÖ‚ñÖ‚ñÅ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà\n","\u001b[34m\u001b[1mwandb\u001b[0m:       train/box_loss ‚ñà‚ñÜ‚ñá‚ñà‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ\n","\u001b[34m\u001b[1mwandb\u001b[0m:       train/cls_loss ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ\n","\u001b[34m\u001b[1mwandb\u001b[0m:       train/obj_loss ‚ñà‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ\n","\u001b[34m\u001b[1mwandb\u001b[0m:         val/box_loss ‚ñÅ‚ñÜ‚ñà‚ñÑ‚ñÑ‚ñá‚ñá‚ñÖ‚ñÖ‚ñÑ‚ñÉ‚ñÖ‚ñÑ‚ñÉ‚ñÑ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ\n","\u001b[34m\u001b[1mwandb\u001b[0m:         val/cls_loss ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ\n","\u001b[34m\u001b[1mwandb\u001b[0m:         val/obj_loss ‚ñÖ‚ñÉ‚ñà‚ñÉ‚ñÑ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ\n","\u001b[34m\u001b[1mwandb\u001b[0m:                x/lr0 ‚ñÅ‚ñÉ‚ñÜ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ\n","\u001b[34m\u001b[1mwandb\u001b[0m:                x/lr1 ‚ñÅ‚ñÉ‚ñÜ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ\n","\u001b[34m\u001b[1mwandb\u001b[0m:                x/lr2 ‚ñà‚ñÜ‚ñÑ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ\n","\u001b[34m\u001b[1mwandb\u001b[0m: \n","\u001b[34m\u001b[1mwandb\u001b[0m: Run summary:\n","\u001b[34m\u001b[1mwandb\u001b[0m:      metrics/mAP_0.5 0.80429\n","\u001b[34m\u001b[1mwandb\u001b[0m: metrics/mAP_0.5:0.95 0.55946\n","\u001b[34m\u001b[1mwandb\u001b[0m:    metrics/precision 0.83825\n","\u001b[34m\u001b[1mwandb\u001b[0m:       metrics/recall 0.72528\n","\u001b[34m\u001b[1mwandb\u001b[0m:       train/box_loss 0.03748\n","\u001b[34m\u001b[1mwandb\u001b[0m:       train/cls_loss 0.0\n","\u001b[34m\u001b[1mwandb\u001b[0m:       train/obj_loss 0.00758\n","\u001b[34m\u001b[1mwandb\u001b[0m:         val/box_loss 0.07574\n","\u001b[34m\u001b[1mwandb\u001b[0m:         val/cls_loss 0.0\n","\u001b[34m\u001b[1mwandb\u001b[0m:         val/obj_loss 0.00515\n","\u001b[34m\u001b[1mwandb\u001b[0m:                x/lr0 0.00101\n","\u001b[34m\u001b[1mwandb\u001b[0m:                x/lr1 0.00101\n","\u001b[34m\u001b[1mwandb\u001b[0m:                x/lr2 0.00101\n","\u001b[34m\u001b[1mwandb\u001b[0m: \n","\u001b[34m\u001b[1mwandb\u001b[0m: Synced \u001b[33mexp2\u001b[0m: \u001b[34m\u001b[4mhttps://wandb.ai/kra0s22/YOLOR/runs/13i0aiif\u001b[0m\n","\u001b[34m\u001b[1mwandb\u001b[0m: Synced 5 W&B file(s), 342 media file(s), 1 artifact file(s) and 0 other file(s)\n","\u001b[34m\u001b[1mwandb\u001b[0m: Find logs at: \u001b[35m\u001b[1m./wandb/run-20221119_172253-13i0aiif/logs\u001b[0m\n"]}],"source":["# run this cell to begin training1\n","%cd /content/yolov7\n","!python train.py --batch 20 --epochs 80 --data {dataset.location}/data.yaml --weights 'yolov7_training.pt'"]},{"cell_type":"markdown","source":["# Solution analysis\n","\n","## Precision\n","Precision measures how accurate is your predictions. i.e. the percentage of your predictions are correct.\n","* $TP = True positive$ \n","* $TN = True negative$\n","* $FP = False positive$\n","* $FN = False negative$\n","\n","$Precision = \\frac{TP}{TP + FP}$\n","\n","## Recall\n","Recall measures how good you find all the positives. For example, we can find 80% of the possible positive cases in our top K predictions.\n","\n","$Recall = \\frac{TP}{TP + FN}$\n","\n","## IoU\n","IoU (Intersection over union)\n","\n","IoU measures the overlap between 2 boundaries. We use that to measure how much our predicted boundary overlaps with the ground truth (the real object boundary). In some datasets, we predefine an IoU threshold (say 0.5) in classifying whether the prediction is a true positive or a false positive.\n","\n","## AP\n","AP (Average precision) is a popular metric in measuring the accuracy of object detectors like Faster R-CNN, SSD, etc. Average precision computes the average precision value for recall value over 0 to 1\n","\n","The general definition for the Average Precision (AP) is finding the area under the precision-recall curve.\n","\n","$AP = $$\\int_0^1 p(r) \\,dx= \\frac13$$$\n","\n","Precision and recall are always between 0 and 1. Therefore, AP falls within 0 and 1 also. Before calculating AP for the object detection, we often smooth out the zigzag pattern first.\n","![PR curve](https://drive.google.com/uc?export=view&id=1JliHoR-0pb25T12X79mk9gH9iPlp-kzZ)\n","\n","Graphically, at each recall level, we replace each precision value with the maximum precision value to the right of that recall level.\n","\n","![Graphs](https://drive.google.com/uc?export=view&id=1pFQ3aWPaMWn3BjWZXA_g_Ph8j4f-mv-x)\n","\n","\n","So the orange line is transformed into the green lines and the curve will decrease monotonically instead of the zigzag pattern. The calculated AP value will be less suspectable to small variations in the ranking. Mathematically, we replace the precision value for recall »ì with the maximum precision for any recall ‚â• »ì.\n","\n","## F1\n","Simply put, it combines precision and recall into one metric by calculating the harmonic mean between those two. It is actually a special case of the more general function F beta:\n","$F1 = \\frac{precision \\cdot{recall}}{precision + recall} \\cdot {Beta}$\n","\n","![F1 curve](https://drive.google.com/uc?export=view&id=1A2ivvryH0N4AOWlLjK76RGbCQbA02Kif)\n","\n","The above training and validation execution ends with the plots exposed in the following link https://wandb.ai/kra0s22/YOLOR/runs/13i0aiif?workspace=user-kra0s22."],"metadata":{"id":"cuf7Dl6X6sdb"}},{"cell_type":"markdown","source":["Due to its long execution time, it is possible to save the trained model on drive for future executions. Besides, it is necesary to save the locally downloaded runs directory on /content/yolov7 directory because of detect.py functionalities."],"metadata":{"id":"GWRVsA-jENxY"}},{"cell_type":"code","source":["%cd /content/yolov7\n","!zip -r export.zip /content/yolov7/runs/train/exp2/weights/best.pt\n","!zip export.zip runs/train/exp2/*"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"hpdolebdCBZh","executionInfo":{"status":"ok","timestamp":1668892348772,"user_tz":0,"elapsed":3843,"user":{"displayName":"jose garcia","userId":"18071348481124640591"}},"outputId":"2d3a729a-bdaf-4dca-d9ed-2327f1c9db3b"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["/content/yolov7\n","  adding: content/yolov7/runs/train/exp2/weights/best.pt (deflated 8%)\n","  adding: runs/train/exp2/confusion_matrix.png (deflated 37%)\n","  adding: runs/train/exp2/events.out.tfevents.1668878485.21ad34bd1da8.553.0 (deflated 71%)\n","  adding: runs/train/exp2/F1_curve.png (deflated 18%)\n","  adding: runs/train/exp2/hyp.yaml (deflated 44%)\n","  adding: runs/train/exp2/opt.yaml (deflated 46%)\n","  adding: runs/train/exp2/P_curve.png (deflated 19%)\n","  adding: runs/train/exp2/PR_curve.png (deflated 18%)\n","  adding: runs/train/exp2/R_curve.png (deflated 17%)\n","  adding: runs/train/exp2/results.png (deflated 9%)\n","  adding: runs/train/exp2/results.txt (deflated 77%)\n","  adding: runs/train/exp2/test_batch0_labels.jpg (deflated 16%)\n","  adding: runs/train/exp2/test_batch0_pred.jpg (deflated 15%)\n","  adding: runs/train/exp2/test_batch1_labels.jpg (deflated 16%)\n","  adding: runs/train/exp2/test_batch1_pred.jpg (deflated 16%)\n","  adding: runs/train/exp2/test_batch2_labels.jpg (deflated 13%)\n","  adding: runs/train/exp2/test_batch2_pred.jpg (deflated 12%)\n","  adding: runs/train/exp2/train_batch0.jpg (deflated 5%)\n","  adding: runs/train/exp2/train_batch1.jpg (deflated 5%)\n","  adding: runs/train/exp2/train_batch2.jpg (deflated 8%)\n","  adding: runs/train/exp2/train_batch3.jpg (deflated 4%)\n","  adding: runs/train/exp2/train_batch4.jpg (deflated 5%)\n","  adding: runs/train/exp2/train_batch5.jpg (deflated 10%)\n","  adding: runs/train/exp2/train_batch6.jpg (deflated 5%)\n","  adding: runs/train/exp2/train_batch7.jpg (deflated 6%)\n","  adding: runs/train/exp2/train_batch8.jpg (deflated 7%)\n","  adding: runs/train/exp2/train_batch9.jpg (deflated 6%)\n","  adding: runs/train/exp2/weights/ (stored 0%)\n"]}]},{"cell_type":"markdown","source":["We will sabe the exported data to our drive"],"metadata":{"id":"z8beRTiy6PRg"}},{"cell_type":"code","source":["%cp /content/yolov7/export.zip /content/drive/MyDrive"],"metadata":{"id":"_RNghnwsCU8r"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":[],"metadata":{"id":"WwCqgeFD6nMj"}},{"cell_type":"markdown","source":["https://datascience.stackexchange.com/questions/16797/what-does-the-notation-map-5-95-mean\n","\n","https://medium.com/axinc-ai/map-evaluation-metric-of-object-detection-model-dd20e2dc2472"],"metadata":{"id":"bCEAnmC6cDbu"}},{"cell_type":"markdown","source":["# Reparametrization"],"metadata":{"id":"RsUEfNAqLziT"}},{"cell_type":"markdown","source":["Reparameterization is used to reduce trainable BoF modules into deploy model for fast inference. For example merge BN to conv, merge YOLOR to conv, ..etc However, before reparameterization, the model has more parameters and computation cost.reparameterized model (cfg/deploy) used for deployment purpose"],"metadata":{"id":"i6m3nNbCBdra"}},{"cell_type":"markdown","source":["1.train custom model & you will get your own weight i.e custom_weight.pt / use (pretrained weight which is available i.e yolov7_traing.pt)\n","\n","2.Converting this weight using Reparameterization method.\n","\n","3.Trained model (cfg/training) and reparameterized model (cfg/deploy) will get same prediction results. However, before reparameterization, the model has more parameters and computation cost.\n","\n","4.Convert reparameterized weight into onnx & tensorrt For faster inference & deployment purpose."],"metadata":{"id":"Lu5gkiB4BfHJ"}},{"cell_type":"code","source":["# import\n","from copy import deepcopy\n","from models.yolo import Model\n","import torch\n","from utils.torch_utils import select_device, is_parallel\n","import yaml\n","\n","device = select_device('0', batch_size=1)\n","# model trained by cfg/training/*.yaml\n","ckpt = torch.load('cfg/training/yolov7_training.pt', map_location=device)\n","# reparameterized model in cfg/deploy/*.yaml\n","model = Model('cfg/deploy/yolov7.yaml', ch=3, nc=80).to(device)\n","\n","with open('cfg/deploy/yolov7.yaml') as f:\n","    yml = yaml.load(f, Loader=yaml.SafeLoader)\n","anchors = len(yml['anchors'][0]) // 2\n","\n","# copy intersect weights\n","state_dict = ckpt['model'].float().state_dict()\n","exclude = []\n","intersect_state_dict = {k: v for k, v in state_dict.items() if k in model.state_dict() and not any(x in k for x in exclude) and v.shape == model.state_dict()[k].shape}\n","model.load_state_dict(intersect_state_dict, strict=False)\n","model.names = ckpt['model'].names\n","model.nc = ckpt['model'].nc\n","\n","# reparametrized YOLOR\n","for i in range((model.nc+5)*anchors):\n","    model.state_dict()['model.105.m.0.weight'].data[i, :, :, :] *= state_dict['model.105.im.0.implicit'].data[:, i, : :].squeeze()\n","    model.state_dict()['model.105.m.1.weight'].data[i, :, :, :] *= state_dict['model.105.im.1.implicit'].data[:, i, : :].squeeze()\n","    model.state_dict()['model.105.m.2.weight'].data[i, :, :, :] *= state_dict['model.105.im.2.implicit'].data[:, i, : :].squeeze()\n","model.state_dict()['model.105.m.0.bias'].data += state_dict['model.105.m.0.weight'].mul(state_dict['model.105.ia.0.implicit']).sum(1).squeeze()\n","model.state_dict()['model.105.m.1.bias'].data += state_dict['model.105.m.1.weight'].mul(state_dict['model.105.ia.1.implicit']).sum(1).squeeze()\n","model.state_dict()['model.105.m.2.bias'].data += state_dict['model.105.m.2.weight'].mul(state_dict['model.105.ia.2.implicit']).sum(1).squeeze()\n","model.state_dict()['model.105.m.0.bias'].data *= state_dict['model.105.im.0.implicit'].data.squeeze()\n","model.state_dict()['model.105.m.1.bias'].data *= state_dict['model.105.im.1.implicit'].data.squeeze()\n","model.state_dict()['model.105.m.2.bias'].data *= state_dict['model.105.im.2.implicit'].data.squeeze()\n","\n","# model to be saved\n","ckpt = {'model': deepcopy(model.module if is_parallel(model) else model).half(),\n","        'optimizer': None,\n","        'training_results': None,\n","        'epoch': -1}\n","\n","# save reparameterized model\n","torch.save(ckpt, 'cfg/deploy/yolov7.pt')"],"metadata":{"id":"z1M_bM6jBagU","colab":{"base_uri":"https://localhost:8080/","height":373},"executionInfo":{"status":"error","timestamp":1668899838993,"user_tz":0,"elapsed":227,"user":{"displayName":"jose garcia","userId":"17007939955126370779"}},"outputId":"5f095b7b-067e-461e-d5f3-ba2299638317"},"execution_count":null,"outputs":[{"output_type":"error","ename":"ModuleNotFoundError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)","\u001b[0;32m<ipython-input-2-1289af013e12>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# import\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mcopy\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mdeepcopy\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mmodels\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0myolo\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mModel\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mutils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtorch_utils\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mselect_device\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mis_parallel\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'models'","","\u001b[0;31m---------------------------------------------------------------------------\u001b[0;32m\nNOTE: If your import is failing due to a missing package, you can\nmanually install dependencies using either !pip or !apt.\n\nTo view examples of installing some common dependencies, click the\n\"Open Examples\" button below.\n\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n"],"errorDetails":{"actions":[{"action":"open_url","actionText":"Open Examples","url":"/notebooks/snippets/importing_libraries.ipynb"}]}}]},{"cell_type":"markdown","metadata":{"id":"0W0MpUaTCJro"},"source":["# Evaluation\n","\n","We can evaluate the performance of our custom training using the provided evalution script and the best results model in /runs/train/exp/weights/best.pt. Similarly to the train.py function, detect.py has a lot of arguments accesible from --help or using the following [webpage](https://github.com/WongKinYiu/yolov7/blob/main/detect.py#L154)."]},{"cell_type":"code","source":["from roboflow import Roboflow\n","rf = Roboflow(api_key=key)\n","project = rf.workspace(\"imagenesyolo\").project(\"additiona-images\")\n","dataset = project.version(1).download(\"yolov7\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"FJOL9gVvcC_-","executionInfo":{"status":"ok","timestamp":1668874439816,"user_tz":0,"elapsed":7357,"user":{"displayName":"jose garcia","userId":"17007939955126370779"}},"outputId":"7704c28b-bb1d-4a26-bce6-6c422df9e8e3"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["loading Roboflow workspace...\n","loading Roboflow project...\n","Downloading Dataset Version Zip in additiona-images-1 to yolov7pytorch: 100% [4447596 / 4447596] bytes\n"]},{"output_type":"stream","name":"stderr","text":["Extracting Dataset Version Zip to additiona-images-1 in yolov7pytorch:: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 162/162 [00:00<00:00, 1187.06it/s]\n"]}]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":6908,"status":"ok","timestamp":1668876151289,"user":{"displayName":"jose garcia","userId":"17007939955126370779"},"user_tz":0},"id":"N4cfnLtTCIce","outputId":"06d42892-8f88-49da-ff75-60ecb9f0894b"},"outputs":[{"output_type":"stream","name":"stdout","text":["/content/drive/MyDrive/Github/YOLOv7_Testing_on_Colab\n","usage: test.py [-h] [--weights WEIGHTS [WEIGHTS ...]] [--data DATA]\n","               [--batch-size BATCH_SIZE] [--img-size IMG_SIZE]\n","               [--conf-thres CONF_THRES] [--iou-thres IOU_THRES] [--task TASK]\n","               [--device DEVICE] [--single-cls] [--augment] [--verbose]\n","               [--save-txt] [--save-hybrid] [--save-conf] [--save-json]\n","               [--project PROJECT] [--name NAME] [--exist-ok] [--no-trace]\n","               [--v5-metric]\n","test.py: error: unrecognized arguments: --source /content/yolov7/additiona-images-1/test/images\n"]}],"source":["# Run evaluation\n","%cp -r /content/yolov7/additiona-images-1 /content/drive/MyDrive/Github/YOLOv7_Testing_on_Colab\n","%cd /content/drive/MyDrive/Github/YOLOv7_Testing_on_Colab\n","!python /content/yolov7/test.py --weights ./runs/train/exp2/weights/best.pt --source {dataset.location}/test/images --name {dataset.location}/test_images\n"]},{"cell_type":"markdown","source":["After the execution of the trained model, it is necesary to test its results and compare them with test's original label. In particular, we will use the IOU measuere to test our real results over the most accurated solutions."],"metadata":{"id":"y0lHoLChHeOs"}},{"cell_type":"code","source":["def bb_intersection_over_union(boxA, boxB):\n","\t# determine the (x, y)-coordinates of the intersection rectangle\n","\txA = max(boxA[0], boxB[0])\n","\tyA = max(boxA[1], boxB[1])\n","\txB = min(boxA[2], boxB[2])\n","\tyB = min(boxA[3], boxB[3])\n","\t# compute the area of intersection rectangle\n","\tinterArea = max(0, xB - xA + 1) * max(0, yB - yA + 1)\n","\t# compute the area of both the prediction and ground-truth\n","\t# rectangles\n","\tboxAArea = (boxA[2] - boxA[0] + 1) * (boxA[3] - boxA[1] + 1)\n","\tboxBArea = (boxB[2] - boxB[0] + 1) * (boxB[3] - boxB[1] + 1)\n","\t# compute the intersection over union by taking the intersection\n","\t# area and dividing it by the sum of prediction + ground-truth\n","\t# areas - the interesection area\n","\tiou = interArea / float(boxAArea + boxBArea - interArea)\n","\t# return the intersection over union value\n","\treturn iou"],"metadata":{"id":"1OcMiIqv5EwQ"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["The following cell will implement the above IOU code for the tested images' labels and the test's label, showing the percentage of solved images (images that detect a weapon on the image), the mean IOU from the detected images and its standard deviation."],"metadata":{"id":"jcdwf6pvIus9"}},{"cell_type":"code","source":["import glob\n","import os\n","import statistics \n","from IPython.display import Image, display\n","%cd /content/drive/MyDrive/Master/CI/Weapon-Dataset-2/\n","i = 0\n","count = 0\n","for path in os.scandir('./test/images'):\n","  if path.is_file():\n","      count += 1\n","data = []\n","best = []\n","for label in glob.glob('./test_images8/labels/*.txt'): #assuming JPG\n","    f = open(label, \"r\")\n","    boxA = f.read().replace('\\n', '').split(\" \")\n","    f.close()\n","\n","    label = label.split(\"/\")\n","    f = open('./test/labels/' + label[len(label) - 1], \"r\")\n","    boxB = f.read().replace('\\n', '').split(\" \")\n","    boxA.pop(0)\n","    boxA = [float(a) for a in boxA]\n","    boxB.pop(0)\n","    boxB = [float(a) for a in boxB]\n","\n","    f.close()\n","    iou = bb_intersection_over_union(boxA, boxB)\n","    if iou > 0.72:\n","      best.append(label[len(label) - 1].replace('.txt', '.jpg'))\n","    data.append(bb_intersection_over_union(boxA, boxB))\n","print(\"Percentage of samples solved is {}\".format(len(data)/count))\n","print(\"Mean of the sample is % s \" %(statistics.mean(data))) \n","print(\"Standard Deviation of the sample is % s \" %(statistics.stdev(data)))\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"6QSD21xj5MMd","executionInfo":{"status":"ok","timestamp":1667675710621,"user_tz":0,"elapsed":61357,"user":{"displayName":"jose garcia","userId":"17007939955126370779"}},"outputId":"ef505361-ae64-47d8-9c4a-234a74b1222c"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["/content/drive/MyDrive/Master/CI/Weapon-Dataset-2\n","Percentage of samples solved is 0.7194805194805195\n","Mean of the sample is 0.6945774779366243 \n","Standard Deviation of the sample is 0.2964602447524831 \n"]}]},{"cell_type":"markdown","source":["The above results shows a decent solve images and a good IOU mean but a bad standard deviation, expossing a not accurated labelling in the images. In addition, the histogram below shows the frequency of IOU values from the tested images.\n","\n"],"metadata":{"id":"VhVk-FasJdl1"}},{"cell_type":"code","source":["import matplotlib.pyplot as plt\n","import numpy as np\n","\n","# An \"interface\" to matplotlib.axes.Axes.hist() method\n","n, bins, patches = plt.hist(x=data, bins='auto', color='#0504aa',\n","                            alpha=0.7, rwidth=0.85)\n","plt.grid(axis='y', alpha=0.75)\n","plt.xlabel('IOU')\n","plt.ylabel('Frequency')\n","plt.title('IOU Histogram')\n","#maxfreq = n.max()\n","# Set a clean upper y-axis limit.\n","#plt.ylim(ymax=np.ceil(maxfreq / 10) * 10 if maxfreq % 10 else maxfreq + 10)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":312},"id":"T-0_dOTdKmK-","executionInfo":{"status":"ok","timestamp":1667675926095,"user_tz":0,"elapsed":448,"user":{"displayName":"jose garcia","userId":"17007939955126370779"}},"outputId":"fbf2ede2-9942-4f60-a605-d9a831155069"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["Text(0.5, 1.0, 'IOU Histogram')"]},"metadata":{},"execution_count":17},{"output_type":"display_data","data":{"text/plain":["<Figure size 432x288 with 1 Axes>"],"image/png":"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\n"},"metadata":{"needs_background":"light"}}]},{"cell_type":"markdown","source":[],"metadata":{"id":"wivJAxg4P93a"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"6AGhNOSSHY4_"},"outputs":[],"source":["#display inference on ALL test images\n","import glob\n","from IPython.display import Image, display\n","\n","i = 0\n","limit = 10000 # max images to print\n","for label in best: #assuming JPG\n","    display(Image(filename='/content/drive/MyDrive/Master/CI/Weapon-Dataset-2/test_images8/' + label))\n","    print(\"\\n\")\n","    "]},{"cell_type":"markdown","metadata":{"id":"aMumI7a2JDAN"},"source":["# Reparameterize for Inference\n","\n","https://github.com/WongKinYiu/yolov7/blob/main/tools/reparameterization.ipynb"]},{"cell_type":"markdown","metadata":{"id":"4jn4kCtgKiGO"},"source":["# OPTIONAL: Deployment\n","\n","To deploy, you'll need to export your weights and save them to use later."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"wWOok8abrCsL"},"outputs":[],"source":["# optional, zip to download weights and results locally\n","\n","!zip -r export.zip runs/detect\n","!zip -r export.zip runs/train/exp/weights/best.pt\n","!zip export.zip runs/train/exp/*"]},{"cell_type":"markdown","metadata":{"id":"f41PvE5gKhYw"},"source":["# OPTIONAL: Active Learning Example\n","\n","Once our first training run is complete, we should use our model to help identify which images are most problematic in order to investigate, annotate, and improve our dataset (and, therefore, model).\n","\n","To do that, we can execute code that automatically uploads images back to our hosted dataset if the image is a specific class or below a given confidence threshold.\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"mcINqQS7Kt3-"},"outputs":[],"source":["# # setup access to your workspace\n","# rf = Roboflow(api_key=\"YOUR_API_KEY\")                               # used above to load data\n","# inference_project =  rf.workspace().project(\"YOUR_PROJECT_NAME\")    # used above to load data\n","# model = inference_project.version(1).model\n","\n","# upload_project = rf.workspace().project(\"YOUR_PROJECT_NAME\")\n","\n","# print(\"inference reference point: \", inference_project)\n","# print(\"upload destination: \", upload_project)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"cEl1NVE3LSD_"},"outputs":[],"source":["# # example upload: if prediction is below a given confidence threshold, upload it \n","\n","# confidence_interval = [10,70]                                   # [lower_bound_percent, upper_bound_percent]\n","\n","# for prediction in predictions:                                  # predictions list to loop through\n","#   if(prediction['confidence'] * 100 >= confidence_interval[0] and \n","#           prediction['confidence'] * 100 <= confidence_interval[1]):\n","        \n","#           # upload on success!\n","#           print(' >> image uploaded!')\n","#           upload_project.upload(image, num_retry_uploads=3)     # upload image in question"]},{"cell_type":"markdown","metadata":{"id":"LVpCFeU-K4gb"},"source":["# Next steps\n","\n","Congratulations, you've trained a custom YOLOv7 model! Next, start thinking about deploying and [building an MLOps pipeline](https://docs.roboflow.com) so your model gets better the more data it sees in the wild."]}],"metadata":{"colab":{"provenance":[{"file_id":"1X9A8odmK4k6l26NDviiT6dd6TgR-piOa","timestamp":1667215164947},{"file_id":"1YnbqOinBZV-c9I7fk_UL6acgnnmkXDMM","timestamp":1657587444672},{"file_id":"1gDZ2xcTOgR39tGGs-EZ6i3RTs16wmzZQ","timestamp":1656523193068},{"file_id":"https://github.com/ultralytics/yolov5/blob/master/tutorial.ipynb","timestamp":1591755516488}]},"gpuClass":"standard","kernelspec":{"display_name":"Python 3","name":"python3"}},"nbformat":4,"nbformat_minor":0}